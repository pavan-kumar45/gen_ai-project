{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: cassio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.9.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cassio) (3.29.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio) (0.2.1.post1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (8.1.7)\n",
      "Requirement already satisfied: six in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.16.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langgraph cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2023.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: langchainhub in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: langchain in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: langchain_huggingface in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-groq) (0.11.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchainhub) (24.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchainhub) (2.32.0.20240905)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (2.9.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.113.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (3.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (6.4.4)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (0.24.6)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (3.0.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (4.44.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.38.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.11.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.3.5)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain_community tiktoken langchain-groq langchainhub chromadb langchain langgraph langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:DHXHpyDSDzDEJgnCEmpMvMhU:bcabbd14b419dce9d8617a4408d370ac37be10d33c26720664744cc7956012a0\"\n",
    "ASTRA_DB_ID = \"4d0ac63c-db4d-4461-a30b-5654bec200c2\"\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Step 1: Load and split documents\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\n",
    "]\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "# print(docs_list)\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 0}, page_content='FACT SHEET 1  \\nWhat is Air Pollution? \\nWhat is air pollution? \\n\\uf0b7Air pollution is the contamination of the\\nindoor or outdoor air by a range of\\ngasses and solids that modify its\\nnatural characteristics. Key health-\\nharmful pollutants include particulate\\nmatter (PM2.5 and PM10) 1, carbon\\nmonoxide (CO), ozone (O3), black\\ncarbon (BC), sulfur dioxide and\\nnitrogen oxides (NOx).\\n\\uf0b7Air pollution is often not visible to the\\nnaked eye as the size of the pollutants\\nare smaller than the human eye can\\ndetect.  T hey can become visible in\\nsome situations for example in the form\\nof sooty smoke  from the open burning\\nof crop residues or other waste, as well\\nas from burning wood, coal, petrol and\\ndiesel fuels for cooking and heating,\\ntransport or power production.   The fact\\nthat you cannot see the air pollution\\ndoes not mean that it does not exist.\\nWhat are the most health \\nharmful air pollutants? \\n\\uf0b7WHO has air quality guidelines for air\\npollutants which are regarded as the\\nmost harmful to health.   These include\\nozone, oxides of nitrogen, sulfur\\ndioxide, and carbon monoxide, as well\\nas fine particulate matter.  Fine\\nparticulate matter (PM 2.5) is the key\\nindicator used in making health\\nestimates of air pollution impacts and is\\nmost commonly measured or\\nmonitored by governments around the\\n1 Particulate less than 2.5 micrometers and 10 \\nmicrometers respectively world to protect citizens against the \\nadverse impacts of air pollutants.  \\nWha t are the main health \\nimpacts of particulate matter ? \\n\\uf0b7The health impacts of particulate matter\\ndepend on the level of exposure\\n(frequently expressed in ug/m3) and\\nthe duration of exposure (which can be\\neither short term  e.g. 8 or 24 hours or\\nlong term e.g. annual)  Individual\\nsensitivity to the health impacts of\\nparticulate matter can vary.\\n\\uf0b7Short-term exposure to particulate\\nmatter (or PM) is likely to cause acute\\nhealth reactions such as irritation to the\\neyes, nose, and throat, coughing,\\nwheezing and increased frequency of\\nacute lower respiratory infections, deep\\nin your lungs.\\n\\uf0b7More prolonged and continued\\nexposure to either high or lower levels\\nof air pollution can also lead to an\\nincreased risk of respiratory infections ,\\nexacerbation of asthma, bronchitis or\\nserious chronic effects including\\nreduced lung function, ischaemic heart\\ndisease, stroke , lung cancer  and\\npremature death . Such symptoms are a\\nparticular concern in rural and peri-\\nurban settings where use of wood,\\nagricultural waste and animal dung is\\nused for cooking, heating and lighting\\nand exposure levels can be high and\\nprolonged over long periods of time.Updated  11 November 2019'), Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 1}, page_content='What are the factors affecting a \\nnormally  healthy person’s \\nvulnerability  to air pollution?  \\nPeople are more vulnerable to having \\nadverse health reactions to air pollution in \\nthe following situations :   \\n\\uf0b7 Particularly high c oncentration s of \\nparticulate matter . A number of \\nfactors, including  increased burning  of \\nfuel for winter, burning  of agricultural \\ncrop residues , as well as particular  \\nweather  patterns can all combine to \\ncreate air pollution peaks.  High \\nconcentrations of particulate matter are \\nmore often found in winter -time when \\nthe temperature and wi nd affect the \\nbuild -up of air pollution and its \\npersistence locally.  Normally, when air \\ngets colder, a layer of warm  air traps a \\nlayer of cold air nearer the ground. This \\nacts like a lid over a cloud of smog and \\nstops it from rising and drifting away .  \\n\\uf0b7 Close proximity  of activities \\ngenerating high levels of pollution \\nincluding:  \\no Heavy traffic on roads, vehicles not \\ncomplying to pollution norms;  \\no Thermal (coal-based ) power plants \\nand other factories emitting \\npolluting smoke;  \\no Uncontrolled construction or \\ndemolition sites;  \\no Use of biomass fuel for domestic \\nenergy needs  such as cooking ; \\no Bursting fire crackers;  o Burning waste from houses, \\nhospitals, electronic waste, crop \\nresidues , etc.  \\nWhat additional factors can \\naffect a person’s vulnerability ?  \\n\\uf0b7 Age of person  exposed : Children,  \\nespecially under -five, and older people \\nare particularly vulnerable.  \\n\\uf0b7 Health status of person exposed .  \\nPeople , with pre -existing diseases such \\nas asthma and other respiratory \\ndisease , cardiovascular diseases , are \\nat greater risk of heal th effects.   \\n\\uf0b7 Pregnant women . Evidence has \\nshown that pregnancy increases \\nvulnerability to the effects of particulate \\nexposure with potential effects to the \\nunborn child such as low and pre -term \\nbirth weight . \\n\\uf0b7 Low socioeconomic status . Persons \\nwith low soci oeconomic status with a \\npre-existing disease,  poor nutritional \\nstatus  and poor housing conditions, \\nincluding where household combustion \\nof solid fuels takes place for cooking, \\nheating or lighting.  People living on the \\nstreet and in poor hous ing are \\nparticularly vulnerable.  \\n\\uf0b7 Occupational  exposures : Construction  \\nworkers, traffic police , road sweepers \\nand those working outdoors and in \\nhighly polluted settings . \\n\\uf0b7 Smoking of tobacco products  and \\nexposure to second -hand smoke')]\n"
     ]
    }
   ],
   "source": [
    "# !pip install pypdf\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Step 1: Load and split PDF documents\n",
    "pdf_path = r\"C:\\Users\\pavan\\Downloads\\what-is-air-pollution-2019.pdf\"  # Replace with the path to your PDF\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Now you have the PDF content split into chunks\n",
    "# You can print or process it further\n",
    "print(doc_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate embeddings using HuggingFace model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Store embeddings in AstraDB\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcassandra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cassandra\n\u001b[1;32m----> 3\u001b[0m astra_vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mCassandra\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdemo3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m astra_vector_store\u001b[38;5;241m.\u001b[39madd_documents(doc_splits)\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\cassandra.py:135\u001b[0m, in \u001b[0;36mCassandra.__init__\u001b[1;34m(self, embedding, session, keyspace, table_name, ttl_seconds, body_index_options, setup_mode, metadata_indexing)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m setup_mode \u001b[38;5;241m==\u001b[39m SetupMode\u001b[38;5;241m.\u001b[39mSYNC:\n\u001b[0;32m    133\u001b[0m     embedding_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding_dimension()\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable \u001b[38;5;241m=\u001b[39m \u001b[43mMetadataVectorCassandraTable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeyspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_indexing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_indexing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_key_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEXT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_provisioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSetupMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOFF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\mixins\\type_normalizer.py:39\u001b[0m, in \u001b[0;36mTypeNormalizerMixin.__init__\u001b[1;34m(self, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     new_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\mixins\\metadata.py:33\u001b[0m, in \u001b[0;36mMetadataMixin.__init__\u001b[1;34m(self, metadata_indexing, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;241m*\u001b[39mpargs: Any,\n\u001b[0;32m     27\u001b[0m     metadata_indexing: Union[Tuple[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_indexing_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_metadata_indexing_policy(\n\u001b[0;32m     31\u001b[0m         metadata_indexing\n\u001b[0;32m     32\u001b[0m     )\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\mixins\\vector.py:39\u001b[0m, in \u001b[0;36mVectorMixin.__init__\u001b[1;34m(self, vector_dimension, vector_similarity_function, vector_source_model, *pargs, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vector_source_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_index_options\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector_source_model))\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\base_table.py:77\u001b[0m, in \u001b[0;36mBaseTable.__init__\u001b[1;34m(self, table, session, keyspace, ttl_seconds, row_id_type, skip_provisioning, async_setup, body_index_options, body_type)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_setup_task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madb_setup())\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\mixins\\metadata.py:94\u001b[0m, in \u001b[0;36mMetadataMixin.db_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdb_setup\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Currently: an 'entries' index on the metadata_s column\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entries_index_column \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_s\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\mixins\\vector.py:67\u001b[0m, in \u001b[0;36mVectorMixin.db_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# index on the vector column:\u001b[39;00m\n\u001b[0;32m     66\u001b[0m create_index_cql \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_create_vector_index_cql(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_index_options)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_cql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_index_cql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCQLOpType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCHEMA\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassio\\table\\base_table.py:579\u001b[0m, in \u001b[0;36mBaseTable.execute_cql\u001b[1;34m(self, cql_semitemplate, op_type, args)\u001b[0m\n\u001b[0;32m    577\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecuting statement \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_cql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as prepared\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    578\u001b[0m logger\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatement \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_cql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has args: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Iterable[RowType], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassandra\\cluster.py:2677\u001b[0m, in \u001b[0;36mcassandra.cluster.Session.execute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\cassandra\\cluster.py:4952\u001b[0m, in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\pavan\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 3: Store embeddings in AstraDB\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "astra_vector_store = Cassandra(embedding=embeddings, table_name=\"demo3\")\n",
    "astra_vector_store.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P. Babakhani et al.: Opinerium: Subjective Question Generation Using Large Language Models\\nof LLMs, offering insights into their performance and\\ncapabilities in this specific subjective context and analyzing\\nthe evaluation metrics and their correlation thoroughly.\\nREFERENCES\\n[1] G. Kurdi, J. Leo, B. Parsia, U. Sattler, and S. Al-Emari, ‘‘A systematic\\nreview of automatic question generation for educational purposes,’’ Int. J.\\nArtif. Intell. Educ., vol. 30, no. 1, pp. 121–204, Mar. 2020.\\n[2] D. Demner-Fushman, W. W. Chapman, and C. J. McDonald, ‘‘What can\\nnatural language processing do for clinical decision support?’’ J. Biomed.\\nInformat., vol. 42, no. 5, pp. 760–772, Oct. 2009.\\n[3] E. Bendig, B. Erb, L. Schulze-Thuesing, and H. Baumeister, ‘‘The next\\ngeneration: Chatbots in clinical psychology and psychotherapy to foster\\nmental health—A scoping review,’’ Verhaltenstherapie, vol. 32, pp. 64–76,\\nJan. 2022.\\n[4] R. Doi, T. Charoenporn, and V. Sornlertlamvanich, ‘‘Automatic question\\ngeneration for chatbot development,’’ in Proc. 7th Int. Conf. Bus. Ind. Res.\\n(ICBIR), May 2022, pp. 301–305.\\n[5] C. Liu, P. Wang, J. Xu, Z. Li, and J. Ye, ‘‘Automatic dialogue summary\\ngeneration for customer service,’’ in Proc. 25th ACM SIGKDD Int. Conf.\\nKnowl. Discovery Data Mining, Jul. 2019, pp. 1957–1965.\\n[6] W. G. Lehnert, ‘‘A conceptual theory of question answering,’’ in Proc. 5th\\nInt. Joint Conf. Artif. Intell., 1977, pp. 158–164.\\n[7] A. C. Graesser and N. K. Person, ‘‘Question asking during tutoring,’’ Amer.\\nEduc. Res. J., vol. 31, no. 1, pp. 104–137, 1994.\\n[8] N. Mulla and P. Gharpure, ‘‘Automatic question generation: A review of\\nmethodologies, datasets, evaluation metrics, and applications,’’ Prog. Artif.\\nIntell., vol. 12, no. 1, pp. 1–32, Mar. 2023.\\n[9] F. Hemmatian and M. K. Sohrabi, ‘‘A survey on classification techniques\\nfor opinion mining and sentiment analysis,’’ Artif. Intell. Rev., vol. 52, no. 3,\\npp. 1495–1545, Oct. 2019.\\n[10] S. Sun, C. Luo, and J. Chen, ‘‘A review of natural language processing\\ntechniques for opinion mining systems,’’ Inf. Fusion, vol. 36, pp. 10–25,\\nJul. 2017.\\n[11] R. Wang, D. Zhou, M. Jiang, J. Si, and Y. Yang, ‘‘A survey on\\nopinion mining: From stance to product aspect,’’ IEEE Access, vol. 7,\\npp. 41101–41124, 2019.\\n[12] C. J. Rameshbhai and J. Paulose, ‘‘Opinion mining on newspaper headlines\\nusing SVM and NLP,’’ Int. J. Electr. Comput. Eng. (IJECE), vol. 9, no. 3,\\npp. 2152–2163, Jun. 2019.\\n[13] Z. Lin, F. Zampetti, G. Bavota, M. Di Penta, and M. Lanza, ‘‘Pattern-based\\nmining of opinions in Q&A websites,’’ in Proc. IEEE/ACM 41st Int. Conf.\\nSoftw. Eng. (ICSE), 2019, pp. 548–559, doi: 10.1109/ICSE.2019.00066.\\n\\nRheinMain. He is currently the CTO of Opinary\\nGmbH, a part of Affinity Global Inc. His\\nexpertise and passion are centered around\\ndeveloping planet-scale real-time AI systems.\\nHis contributions are evident in his publications\\nsuch as Collaborative Filtering: für automatische\\nEmpfehlungen and News Recommendation in\\nReal-Time by Springer International Publishing.\\nHe presented at AWS:reinvent on cloud-native architecture and is also\\ndedicated to mentoring in coding and startups. His blend of academic\\nexcellence, professional achievements, and mentorship highlights his\\ninfluence in the ever-evolving technology landscape.\\nDOREEN SACKER received the B.Sc. degree\\nin information systems and management from\\nMunich University of Applied Sciences, and the\\nM.Sc. degree in international media and comput-\\ning from Hochschule für Technik und Wirtschaft\\nBerlin. She is currently an active and senior\\ncontributor to the fields of data science, MLOPS,\\nand natural language processing. Additionally, she\\nis a co-host of UNMUTE IT, a podcast series\\ndedicated to women in tech.\\nFIKRET SIVRIKAYA received the bachelor’s\\ndegree in computer engineering from Bo ˇgaziçi\\nUniversity, Istanbul, Turkey, in 2000, and the\\nPh.D. degree in computer science from Rensselaer\\nPolytechnic Institute, Troy, NY, USA, in 2007.\\nSince 2008, he has been a Senior Researcher\\nand a Lecturer with Technische Universität Berlin\\n(TU Berlin), Berlin, Germany. Since 2016, he has\\nbeen the Research Director of German–Turkish\\nAdvanced Research Center for ICT (GT-ARC)\\ngGmbH, an affiliated institute of TU Berlin. His research interests include\\nfuture mobile networks, the Internet of Things, and artificial intelligence,\\nwith an application focus on intelligent transport systems and smart cities.\\nSAHIN ALBAYRAK received the Ph.D. and Habil-\\nitation degrees in computer science from Tech-\\nnische Universität Berlin (TU Berlin), Germany,\\nin 1992 and 2002, respectively. He is currently\\na Full Professor of business applications and\\ntelecommunication (AOT) with the Chair of Agent\\nTechnology, TU Berlin. He is the Founder and\\nthe Head of the Distributed Artificial Intelligence\\nLaboratory (DAI-Labor), TU Berlin. He is also the\\nFounding Director of the Connected Living Asso-\\nciation, German–Turkish Advanced Research Centre for ICT (GT-ARC)\\ngGmbH, and the Center for Tangible AI and Digitalization (ZEKI), Berlin,\\nGermany. His research interests include distributed systems, machine\\nlearning, cybersecurity, multi-agent systems, and autonomous systems, with\\ntheir particular applications in autonomous driving, smart cities, smart\\nenergy systems, telecommunications, and preventive health.\\nVOLUME 12, 2024 66099\\nspanning, yes/no, and deep understanding [8]. Similarly,\\nwe divide questions into two groups objective questions\\nwhere the answer is retrievable from the given text regardless\\nof answer types, and subjective questions where a subjective\\nanswer is provided by individuals and the text only provides\\na particular topic to be questioned. Precisely, objective\\nquestions are questions that seek objective information or\\ndata that can be verified or retrieved based on the given\\ntext. On the other hand, subjective questions ask for a\\nsubjective perspective, belief, or judgment on a particular\\ntopic related to the text. Individually, answers are based on\\npersonal experiences, preferences, circumstances, and values.\\nThis taxonomy is regardless of the form of possible answers\\nwhich can be yes/no or multi-sentence spanning texts.\\nThe primary distinction between objective and subjective\\nquestion generation relies on the source of the answer, which\\ncan be the text or personal preferences or opinions of an\\nindividual. Furthermore, objective and subjective questions\\nare semantically and comprehensively different. Table 1\\nillustrates the syntactic and semantic differences between\\nthese two question categories with objective and subjective\\nquestion examples for the given context. All of the objective\\nquestions can be answered according to the text despite the\\nsubjective questions aiming to ask the reader’s perspective.\\nTABLE 1. Subjective and objective questions based on a given text.\\nSimilar to the text and subjective questions above,\\nour focus lies on generating relevant and meaningful\\nopinion-based or feedback-based questions from a paragraph\\nto directly ask the opinions or personal preferences of users.\\nTherefore, subjective question generation is an intersection\\nof question generation and opinion mining domains [9],\\n[10], [11], [12]. Particularly, it aims to generate a set of\\nquestions, prompts, and queries to elicit feedback or opinions\\nfrom a group of human individuals. Certainly, an ideal\\nsolution requires interpreting a topic comprehensively and\\ngenerating an opinion question syntactically and gram-\\nmatically correct. However, there are several possible and\\nrelevant subjective questions according to a corpus of text.\\nPotential applications can be automatic generation of surveys\\nand polls [13], question answering [14], public opinion\\nengagement analysis [15], opinion or feedback mining\\n[16], chatbots [17], opinion spam classification [18], and\\ncustomer opinion mining [19]. Generally, automatic question\\ngenerator systems follow two approaches open-domain andclosed-domain. In the closed-domain approach, the ques-\\ntioner system is capable of generating questions on particular\\ntopics. In contrast, the open-domain approach aims to gener-\\nate questions in a wide range of domains by adopting an end-\\nto-end method, resembling sequence-to-sequence generation\\n(aka machine language translation) to generate questions.\\nIn this study, we are focusing on open-domain question\\ngeneration aiming to generate questions on various topics.\\nOver the years, AQG techniques have evolved significantly,\\ntransitioning from classic rule-based [20] and template-\\nbased [21]methods to neural network methods [22]and trans-\\nformer architecture [23]. Recently, with the new advances in\\nthe transformer architectures, several large language models\\nsuch as GPT [24], flan-T5 [25], and LLaMA [26], have\\ngained attention as the state-of-the-art in natural language\\nprocessing due to their impressive capacity to understand\\nand generate humanoid text. These models are trained on\\nan extensive text corpus, allowing them to capture complex\\npatterns and structures in languages. Therefore, automatic\\nquestion generation using large language models has emerged\\nas a promising solution, leveraging the capabilities of these\\nmodels to generate questions from given text. Technically,\\nthe performance of these models depends on the number of\\nparameters and trained tokens regardless of the architecture\\nfamily and all of these models can be scaled to larger models\\nfor a wider range of tasks. Figure 1shows the number of\\nparameters for the state-of-the-art transformers.\\nFIGURE 1. Number of parameters for various large language models.\\nAdditionally, applying the fine-tuning [27] method uti-\\nlizing these large language models is becoming a common\\napproach to tackle new downstream linguistic tasks, where\\nthe models are trained to generate questions with minimal\\nsupervision or training data. Fine-tuning techniques leverage\\nand transfer the pre-trained knowledge of large language\\nmodels to generalize them to wider tasks.\\nIn this study, we comprehensively investigate the pos-\\n[45] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac,\\nT. Rault, R. Louf, M. Funtowicz, and J. Davison, ‘‘TransFormers: State-\\nof-the-art natural language processing,’’ in Proc. Conf. Empirical Methods\\nNatural Lang. Process., Syst. Demonstrations, 2020, pp. 38–45.\\n[46] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,\\nT. Killeen, Z. Lin, N. Gimelshein, L. Antiga, and A. Desmaison, ‘‘PyTorch:\\nAn imperative style, high-performance deep learning library,’’ in Proc.\\nNIPS, Dec. 2019, pp. 8024–8035.\\n[47] N. Shazeer and M. Stern, ‘‘Adafactor: Adaptive learning rates with\\nsublinear memory cost,’’ in Proc. 35th Intl. Conf. Mach. Learn., vol. 80,\\nJul. 2018, pp. 4596–4604.\\n[48] OpenAI. (2021). OpenAI API. [Online]. Available: https://openai.com\\n[49] K. Blagec, G. Dorffner, M. Moradi, S. Ott, and M. Samwald, ‘‘A\\nglobal analysis of metrics used for measuring performance in natural\\nlanguage processing,’’ in Proc. 1st Workshop Efficient Benchmarking NLP,\\nT. Shavrina, V. Mikhailov, V. Malykh, E. Artemova, O. Serikov, and\\nV. Protasov, Eds., Dublin, Ireland, May 2022, pp. 52–63.\\n[50] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\\nof deep bidirectional transformers for language understanding,’’ in Proc.\\nConf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang.\\nTechnol., vol. 1. Minneapolis, MI, USA: Association for Computational\\nLinguistics, Jun. 2019, pp. 4171–4186.\\n[51] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\\nL. Zettlemoyer, and V. Stoyanov, ‘‘RoBERTa: A robustly optimized BERT\\npretraining approach,’’ 2019, arXiv:1907.11692.\\n[52] C. Spearman, ‘‘The proof and measurement of association between two\\nthings,’’ Int. J. Epidemiol., vol. 39, no. 5, pp. 1137–1150, Oct. 2010.\\nPEDRAM BABAKHANI received the Bachelor\\nof Science degree in computer engineering from\\nShahid Beheshti University, Tehran, Iran, and the\\nMaster of Science degree in data analytics from\\nthe University of Hildesheim, Germany. He is\\ncurrently pursuing the Ph.D. degree in computer\\nscience with the Distributed Artificial Intelligence\\nLaboratory (DAI-Labor), Technische Universität\\nBerlin, Germany. His research interests include the\\nintegration of natural language processing, large\\nlanguage models, interactive environments, and the Internet of Things to\\nimprove human-space interactions.\\nANDREAS LOMMATZSCH received the Ph.D.\\ndegree in computer science from Berlin Institute\\nof Technology. He is currently a Senior Researcher\\nand the Director of the Competence Center\\n‘‘Artificial Intelligence and Machine Learning,’’\\nDAI-Labor, TU Berlin. His research interests\\ninclude distributed knowledge management com-\\nbining semantic modelling and natural language\\nprocessing algorithms for smart assistants and\\nconversational systems. He has many years of\\nexperience in the field of data stream-based recommendations and reliable\\nchatbots.\\nTORBEN BRODT received the B.Sc. degree\\nin computer engineering from Hochschule'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you want to retrieve the top N results\n",
    " # Set this to the number of top results you want\n",
    "\n",
    "retriever = astra_vector_store.as_retriever()\n",
    "\n",
    "# Modify the invoke method to include a parameter for the number of top results\n",
    "results = retriever.invoke(\"Methodology\", ConsistencyLevel=\"LOCAL_ONE\")\n",
    "\n",
    "retrieved_content = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "# print(retrieved_content)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    # Split the text into lines and remove duplicate lines\n",
    "    lines = text.split('\\n')\n",
    "    unique_lines = list(OrderedDict.fromkeys(lines))  # Preserve the order and remove duplicates\n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "cleaned_text = remove_duplicates(retrieved_content)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "# astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "# groq_api_key = \"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\"\n",
    "# llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-70b-versatile\")\n",
    "# answer = astra_vector_index.query(\"Instruction Prompting\", llm=llm).strip()\n",
    "# print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='pretrained_model'\n",
      "datasource='pretrained_model'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Set up ChatGroq for routing logic\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"pretrained_model\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to vectorstore or pretrained model.\",\n",
    "    )\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-70b-versatile\")\n",
    "structured_llm_router = llm.with_structured_output(schema=RouteQuery)\n",
    "# Define a schema for routing\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Schema to determine whether to route to vectorstore or pretrained model.\"\"\"\n",
    "    datasource: Literal[\"vectorstore\", \"pretrained_model\"]\n",
    "\n",
    "# Define a system prompt for routing\n",
    "system = \"\"\"You are an expert at routing a user question. \n",
    "Use the vectorstore for questions related to Prompt Engineering. \n",
    "else use pretrained model\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Specify the schema in with_structured_output\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"who is Sharukh Khan?\"}\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What is ML?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the LangGraph workflow\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Define GraphState\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    generation: str\n",
    "\n",
    "# Define the retrieve node (vectorstore querying)\n",
    "def retrieve(state):\n",
    "    print(\"---RETRIEVE FROM VECTORSTORE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    # Join document content into a single string to pass it to the LLM for question generation\n",
    "    retrieved_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    # Pass the retrieved content to ChatGroq for question generation\n",
    "    llm_prompt = f\"Based on the following document content, generate three questions:\\n{retrieved_content}\"\n",
    "    questions = llm.invoke(llm_prompt)\n",
    "    return {\"generation\": questions, \"question\": question}\n",
    "\n",
    "# Define the LLM query node (direct pretrained model query)\n",
    "def llm_query(state):\n",
    "    print(\"---PRETRAINED MODEL QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    llm_prompt = f\"Generate three questions about the topic: {question}\"\n",
    "    questions = llm.invoke(llm_prompt)\n",
    "    return {\"generation\": questions, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the routing node\n",
    "def route_question(state):\n",
    "    \n",
    "    print(\"---ROUTING QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # Routing based on topic\n",
    "    if source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE TO VECTOR STORE----\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"---ROUTE TO PRETRAINED MODEL----\")\n",
    "        return \"llm_query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# Step 6: Build LangGraph workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)  # Retrieve from vectorstore and pass to LLM\n",
    "workflow.add_node(\"llm_query\", llm_query)  # Query the LLM directly\n",
    "\n",
    "# Define conditional edges for routing\n",
    "workflow.add_conditional_edges(\n",
    "    START, route_question, {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"llm_query\": \"llm_query\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# End nodes after retrieval or LLM query\n",
    "workflow.add_edge(\"retrieve\", END)\n",
    "workflow.add_edge(\"llm_query\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADbAOEDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYHBQgBAwQCCf/EAEwQAAEDBAADAwcHBQ4FBQAAAAECAwQABQYRBxIhEzFBCBQWIlWU0xUyUVRhldE2VnWRkhcjJDhCU3FydIGTsrO0CTM1N7FSd4Kitf/EABsBAQEAAwEBAQAAAAAAAAAAAAABAgMEBQYH/8QAMxEBAAECAwMKBQQDAAAAAAAAAAECEQMSUQQhMRMUQVJhcZGhsdEFFSKBwSMzU+EyQvD/2gAMAwEAAhEDEQA/AP1TpSlApSlApSlApSlApSo5Klzcklvw7bIXb4EdZak3FCAXHFjvbY3sDlPRSyCAQUgFXMUZ0UZuyFiGclTo0FAVJkNR0nuU6sJB/XXi9KrL7Yge8o/GvHEwDHoiy4bTHlSDoqlTU+cPqI7iXHOZR7z4+Jr2eitl9jwPdkfhW22DHTM+H9m49KrL7Yge8o/GnpVZfbED3lH409FbL7Hge7I/CnorZfY8D3ZH4U/R7fJdx6VWX2xA95R+NPSqy+2IHvKPxp6K2X2PA92R+FPRWy+x4HuyPwp+j2+RuPSqy+2IHvKPxp6VWX2xA95R+NPRWy+x4HuyPwp6K2X2PA92R+FP0e3yNz2xZ0acgqjSGpCR3lpYUB+qu+o9MwDHZiw58kxo0gbKZUJPm76Se8hxvlUPDuPhXxGlzcZlMRLlIcuFufWlqPcFoAcaWeiW39aB2dBKwBskJI5tFcyUVftzv0n8f9CW0SSlKVoQpSlApSlApSlApSlApSlApSlApSlApSlBhM1uz9lxa4SopSmZ2YajqWNpDy1BDZI8RzKTuvdZrVHsVqiW+KkpYjNpbRzHZOh3knqSe8k9SSTWH4jtKXhs95CVLMQtTilKeZSgy6h4gDxOmzoVI23EutpWhQWhQCkqB2CPprondgxbWfSLesr0PqlKVzoh/EHi5ifC025OS3QwnrgXBFjsxXpLz3IAXFBtlC1cqQQVK1obGyN1EJnlJWKJxktWD+aznmLjZ27kzco9vlvJUt11tDSNIZISgpXzF1SglJ0FFJrE+U3DbbVYLvb7dmKMvt7UtVmveI20zfNXFJRtiS3pSVNOkJ6KTy/vZ9ZHQnCs3PLcZ4sYFm2WYpdZT1zwkWi5px+CuYIVyL7Ly0OJb2UI+eArqkFOt+NBZo4/YF6cpxBV+7K/KlGChp6G+2yuQN7ZS+psNKc6H1Qsnw1XzL8oDBomRXSwi6Spd4tbymJsODapkpcdQaDvrhppWgUH1VdyiClJKgQNbM7gZnkd0Em+2bP7rk1oziLcPN4bD/yJGtTE9Kmlx0IIbkK7EJPQLdCirYABq++COPTbRnPGKZNtsiELjlAejPvsKbElkQYyQtCiPXQFBwbGxsKHfug93k/ccoHHjBo19jQZVsllAXJiPRZCG2ipSwkNvONoS90R1U3sA9+tirOqj/JKkXCw8L7Zg95x+9WW9Y425GlOT4K2orx7ZzSmHiOR1JGlbST0NXhQK8l3tce92yVAlpK48ltTSwDo6I1sHwI7wR3HrXrr5WtLaSpRCUpGySdACrEzE3jiMLhF0fvGLQJEtSVzUpUxJWkaCnm1FtwgeAK0KOqzlRnhw2oYfDfUlSPPXH54StPKoJfeW8AR4HTg6VJq248RGLXEcLz6rPEpSlaUKUpQKUpQKUpQKUpQKUpQKUpQKUpQcKSFAggEHoQfGorbpTeDBq1T1pZswPJb5qyQhpP8lh1R6JI+agnooAJ+cPWldfDrSH2ltOoS42sFKkLGwoHvBHiK20VxETTVviVhEMo4M4Fm92VdMhw2xXu5KQltUufb2nnSkdw5lJJ0KxSvJu4UrCQrhxi6ggaSDaWOg2Toer9JP66jbk+Fd87ynAcNayHG7zabaJAuoZdFlZkLSCy0EqPIo6WFFKAkEJI3sdJViHDi/WrG4MW+Z3ebtdm0fwmYx2bLbiySTyoUlZAG9Daj3Vnkw54V+Me1y0JJiOCY5gEB6FjNit9ghvO9s4xbYyGELXoDmISACdADf2Cs7UX9CZH51X7/ABmfhU9CZH51X7/GZ+FTk8Pr+Ulo1SilRf0JkfnVfv8AGZ+FT0JkfnVfv8Zn4VOTw+v5SWjV7MuwbHc+tzUDJbHb7/BadD7ce4xkPtpcAKQsJUCAdKUN/QTUTHk2cJxvXDfFhvv1aWOv/wBakHoTI/Oq/f4zPwqxGW8OL5dccnxbLnV5tV1cb1GmPdm6htewQVISlBI6aOlDvpyeH1/KS0avfinB7BcFuhuWOYfZLFcC2WTKt8BplwoJBKeZKQdEgdPsFdtxmIzgO2q3uJetBJbuE5tRKFp/lMNKHRSj81RB0kEj53dXyJ0SyZtiWB5q3kWS3m8W8vKuwadNldkoSS60pKTypJCFKCVhQCSNnZ63Syy3HaQ00hLTSEhKEIGkpA7gB4CkTRh76ZvPlHv5G6H0lIQkJSAlIGgANACuaUrnQpSlApSlApSlApSlApSlApSlApSlApSqll8SZ3GCwZzZuF9yVZclsc1NrVd73anfNUPBenuyCgO0UgJWO4gK5dgpUCQsGdmFkt+QQrA/doLV/nNrdiWxyQlMh9KASpSUb5iAAdkDwNVqjDL35QWARmOJVnnYKpu7+eIs9lvau0fjN77NuS42BsKJ5ilJ6cqCCk9BPLTgFrj3e3ZFc4UC55nHtzdueyAREtvOJTsr5epLaVKUpXKD05tbOqk9BwBoAVzSlApSlApSlApSlAqnXMLvXADAbgjhpZ52cPPXbz5VmvV7VzMsL12rcZxwHWiOYJUepWskqOgbipQYaDmNln5BKx9u6wV5DDZbflWtuSlUhhCxtKlI3sA+B14j6RWZqM3XArXIvU3I7fBgW/Mnbe5b2L+qGlx5pCtFPN1BWlKkpPKSO7Wxs1CYnEe4cGsbwq08Ubou+5Hep5tabvZLS75sp0qIZ7UJBCFLBQOgAKidDlSVALcpSlApSlApSlApSlApSlApSlApSlBT13fsXFHjsxYU3zJLddMBDN0kW6E+GIE1UhO2S6RtTnKAocvQeuQdirgCQkaAAHf0qEWC65RI4r5VBn49Fh4rHixVW29N67aa6pJ7ZC/WJ0g6A9Ud/jU4oFKUoFKUoFKUoFKUoFKUoFKUoFcEBQ6jfj1rmlBT1vesXC3jwqzLvmST7pxCD0+NbZb4fgQ1xm9vKb3pTfMkoHKNj1AOg1q4ag+R3XKI3FTEINux6LOxeSxMVdby5rtoK0oBZSj1gdLVsH1T3eFTigUpSgUpSgUpSgUrhSghJUohKQNkk9AKhRzC93YCRZbZBNtX1ZkXCSttx5PgsNpbPKk942dkd4FbsPCqxb5fZbXTalQj5dzD6hY/e3vh0+Xcw+oWP3t74dbua16x4wWTeqm8qPgqzx64LX3GORJugR55a3FEDs5jYJb6nuCtqbJ8EuKqRfLuYfULH7298Ony7mH1Cx+9vfDpzWvWPGCz8Q+HXDG8cRuJtnwiFHWzd584QlIdbO4+j++LWnoQEJClKHeAk1+7mIYzDwrE7Jj1v5xAtEFiBH7Q7V2bTaUI2fE6SK18wvyeXcG485TxTgwLMbrfGuUQ1SHOyiuLIL7qD2e+ZwpBJ8OZfgrQuP5dzD6hY/e3vh05rXrHjBZN6VCPl3MPqFj97e+HT5dzD6hY/e3vh05rXrHjBZN6VCPl3MPqFj97e+HXst+WXCNNjR75BjRkSVhpmVDfU632h7kLCkJKdnYB6gkAHRIBxnZsSIvun7wWSulKVyoUpSgUpSgUqHP5fdbm44qxQIb0FC1NplzpC2+2Uk6JQhKFepsEBRI3rYBSQo9Py7mH1Cx+9vfDrrjZcTptH3hbJvWKyzGoWZ4tecfuSVqt12hPQJKW1cqi06goWAfA6UetR35dzD6hY/e3vh0+Xcw+oWP3t74dXmteseMFn4i8TuGF34X8TL1hNwYW7dLfMMVAbQdvpJBaWhPU6WkpUB36UK/ZXyVuCzfAXgnYsZWhIuq0mddHE/y5bgBWN+PKAlsHxDYNQLOfJ6ez3jpifE+fAsybrYUcqogkOlqWtJJYWv8Ae+im1EqBHU6QD0To3F8u5h9Qsfvb3w6c1r1jxgsm9KhHy7mH1Cx+9vfDp8u5h9Qsfvb3w6c1r1jxgsm9KhScnyeGe2mWe3SYyeriIEtwva8ShKmwFH7OYf01LYE+PdIMeZFcD0Z9CXG3B3KSRsGtOJg14e+rh4lnopSlaUYvKCU4zdyDoiG8QR/UNR7GQBjdqAAAERrQH9QVIcq/Ji8f2N7/ACGo9jX5OWr+yNf5BXo4P7M9/wCF6HSjMbA5CjzE3y2qiSJfmDMgS2y25J5y32CVb0XOcFPIOvMCNbFZitQbR/2ZwL/3YH/7UipNxGzjiA3cuOE2z5ibPBwViPNt8BFsjvJf3b25Djbq1pKigqCtculArPrEAJGOZGzFKpHBcqy+1cVccsd+yMZFb8kxx68BC4LUcwZDS2ApLRbAJaKX+5ZWoFI9Y9atXNMjTh+HX2/KYVJTa4D84spOi4Gm1L5R/Ty6rKJuMzSta7VlXEq1t8JL/eM1ZnsZrdY7cyzR7Ww3HitPRHpCW2XNFwhPIlJUoknvBT3Hui8W8sc8nCyZSq67v0nJ0W52X5s160c3tUUo5OTlH7yAjYG/He+tTNA2OpWqUzixxaze5ZXdcMt97cjWm7SrZbbdGt9sct8ox3C2fOXXpCJAK1JVsthPIFDQWRsznHbrnefcY86tRyt/GbHYTa1tW+JCivPc70VLrrSnXG1epvfUettXRQA0Wa4vSsBm55bNGI7xc7dr7P4azVLYZxdyrKneHuIruCWsxYu02Nlb7cds7Yt/qunl5eVAkKcikFIGg8eXXhdGc/8ARY36Tt3+9ZrfgTfEp74ZU8YWHSlK8hiUpSgUpSgrnhwebAMcUe829gn+koFSOo3w2/7fY3+jmP8ATFUrZeImZRLNxVzq75I7KsuHXe8sQ8fjwo6EymY6FFtDzvZlfRRTopKT6u1FW9D2Nom2LV3ys8ZbHV8ocQ6CUKSsAlJKTvRB0R+utbuHGVcY7rfcakz4t9l2e7pJua59vtUaLBQtkqQ9EUzIcdUEr5AEupXzJJJII1UX4czMn4ceSRnGUwcumyZkT5ZcgsyIkQtxXm58gF1OmgVFZBUQsqSCegA0K583YjbC43iBZxGM+bGhCS+iMwZLqW+1eWdIbTsjmUrwSOp8K9da8Z9GzDHWOGNwu+YG9uXDK7czLgPWiF5qjtRshnbJcRyFKuVfPzjmPrd2ozM4scWs3uWV3XDLfe3I1pu0q2W23RrfbHLfKMdwtnzl16QiQCtSVbLYTyBQ0FkbLMNraVrjlfF7MsWm5riTskIy66uW9zEO2ZaJZTN0ypBCU8rgiutvLJVvaQOYkVhrtxN4p5XkeYMYgi/usYzOVZo3mFttb0ebJaabUtctT77bieda/mspQEpIIJJ0GaBtPXRwuO8CtH2IUB9g51aryYzMuFxxu1S7tCFtur8Rp2XCCwsR3lIBW3zAkHlUSNgneq9XC38grT/UX/qKrLE/Ynvj0qXoSulKV5qMXlX5MXj+xvf5DUexr8nLV/ZGv8gqXTYiJ8N+M7vsnm1Nq136I0f/ADVfxLlJxeFGtlztdydeitpZEqDBcktPhIACx2SVFO9dUqAIOx1GifR2f6sOaI43ZRvhD5Xk5Y3Ix+92VFwvUWDcLuL7HSxMCVWuYHe17SIeU9ntwlWjzDZOgKyc/gnZblD4gx351yX6bxkRbm52rfMhKYojBTXqaSooGzzBQ5uutdKkXpnG9mX77kl/Cp6ZxvZl++5Jfwq3chX1ZMs6MFeOHgt93s2TWVlVyv8AYbU7aYMKZNEaM806pkrLq0srUFAMggpGu8a67HzEuOfXeQiDe8Jxxmzydsy1tZG7IUGlDStNqhIC+hPqlQ39NZ/0zjezL99yS/hU9M43sy/fckv4VORxOrKZZUvP8m6ViN+4anGLxkN4sVjyBEhVqulxaci2yII0hG2gpKVqCVLbQAVLUATrpupNN8mDH5oMUX/JI1kTd03xiyMTGxDjyhIEhRQktFRQpzmJQpSkjmJSEnREwi8V8fm3ubZo5uL94goQ5Kt7VrkqfjoWNoUtsN8yQodxI6+FZL0zjezL99yS/hVOb19WVyzoh73AC1N5Xcb1aciyXHGrnMFwuFqtFwDMOXI6czqklBUlS+Uc3IpPNrrupXYcDt+PZflGRxnpK52QqjLlNuqSW0FhrskdmAkEbT1Oyevdrurt9M43sy/fckv4VPTON7Mv33JL+FV5CvqyZZ0V5wj4az4nE/OuI99sbWPXXIfN4rFvTKRIcaYZQEqcWtHqBTpSglKSdBtOzvdWFnP/AEWN+k7d/vWa59M43sy/fckv4Vc8kjMn4cVm3zIkBqSzKkSp0ZTHRpaXEoQhYClKUpKQToAAKO96BzoonCqiuuLRG8iJibysGlKV4rEpSlApSlBXHDb/ALfY3+jmP9MV5sd4YWXHrTk9sCXrhAyK4TLhPYnFK0qVJ/5rYASPU10AOzo9Sa9EBT+EQWrRMt0+QxDT2UeVAiLkodaHRGw2klKgNAgjwJBIru9M43sy/fckv4Ve3iUVYldVdEXiZllMTM7kY4e8E4nDebFVByrKZ9shMqjwrNcriHYcVs6ASlIQFKCQAE9opXKO6sY55N9iVZcwsbd9yBnHsmbkpes6JTRjRFyF9o65HCmipCirmOlFSRzq0OtTr0zjezL99yS/hU9M43sy/fckv4Va+Qr6smWdHny3h7bsyj48zNelNJsdzjXWMY60grdY3yJXtJ2k7OwNH6CKi73AC1N5Xcb1aciyXHGrnMFwuFqtFwDMOXI6czqklBUlS+Uc3IpPNrrus9L4r4/AvUCzyTcY93uCXFw4DtrkpfkJQNuFtBb5lBIOyQDrxrJemcb2ZfvuSX8KnIV9WTLOjovfDmxZDm+OZZNi9rerAiQ3Be2NIDyQlexrr0HT6OY/TUWv3AG1XXKrpfrbkWS4rIu/Iq6R7BcBHZnLSnlC1goUUr5QAVNlBIHU761MPTON7Mv33JL+FT0zjezL99yS/hU5Cuf9ZMs6M+BoAf8AmvPwt/IK0/1F/wCoqsUjKHJygzb7Ld5EpXRCZMB6K2D9KnHUpASO862ddwJ0DK8Wsno5j1vtpcDy47QQtwDQWvvUoDwBJJ1WrH+jCyVcZmPKJ9zhG9laUpXmsSlKUClKUClKUGu3DP8Ajq8Z/wBDWX/TVWxNa7cM/wCOrxn/AENZf9NVbE0ClKUClKUClKUClKUClKUClKUClKUGu3FX+OdwL/R19/26K2JrXbir/HO4F/o6+/7dFbE0ClKUClKUClKUClKUClKUClKUGtvDq5w43lx8XoT0thqZKstoUxHW4lLjwQ0SsoSTtXKCN67tjdbJVV/GfydcR42Mx5F0YeteRwtKt2SWlfYXCGsHaSlwdSAevKrY6kjR61V0PjLxA8muS1auMsZeT4ZzBqLxEs8YnshvSRPYTsoPd66dg9B65JIDaGlY+w3+2ZTZ4t1s9wjXS2SkBxiXEdS606n6UqB0ayFApSlApSlApSlApSlApSlApXgvl9tuMWiVdbvPjWy2xUFx+XLdS200keKlEgAVrbN41Z/5SMp208F4qsdxDnLUviLeY5CVjelCCwoAuK7xzq0Adj1DpVB7+J9zhyfLc4KQWZbDs2LbL0p+Mh1JcZC46eQrSDtIVyq1vv0dd1bJVVvBjyc8S4KNyJduafvGTztquOS3dfbz5iydqKnD81JP8lOh0G9nrVpUClKUClKUClKUClKUClKUClKUCuqVFZmxnY8hluRHdQW3GnUhSFpI0UkHoQR4V20oNbr75OORcIrxKyjgRc2bMp5Zfn4LclE2e4HxLXXcZw+BTpPzR6qQQZlwj8pSx8SLs7i94gysI4gxB/CsWvOkPnpsrYX0D7fQkKT10N6A0Tb9aof8RRcaLwhhvRMLdyTKVywi3XWPGkdpZkpHMuSH2k+qQQgJbUtIUVc2lhtSaC4OH/lG4XxM4nZjgdllyFX7F3C1LTIa7ND5SrkdLOzzKDbnqKJSkbIKeZJCqs+vwZ4OcS75wP4pWXK7Y04J1sf5noiwU9uyocrjShroFIJG9dCQR1Ar9xcHzyy8Q8QtGS2WYiRa7pGTJYWSArlPelQ8FJO0keBBHhQSGldXnTP883+0KedM/wA83+0KtpHbSurzpn+eb/aFPOmf55v9oUtI7aV1edM/zzf7QrD5hm1mwTFrrkV5mtxbVbIy5Ul3YJCEjegPEnoAB1JIA76WkRHiD5Q2G8MuI+G4Re5jyL5lT3YQ0MNdoloqVyNF7R5kpccPZpIBHNvfKkFQxvF3ykrDw0ujONWuHKzTP5Y/geLWUdpIPTYW8rqGG+oJUrw6gEA1+PXGTibfePHFO9ZTcGnnJdweJjw2wV+bsDo20kfQlIHXXU7J6k1+mf8Aw7fNpHCae9Nwx7HMubmFu53WVHkdreARzIkKfeHrKJKwptK1BKk82kBxIqDO2TydMl4w3eLk3He5M3RLKw/AwO2LItME+Be67kuDxJJT84eskgDYyJEYgRWY0VluNGZQG22WkBKEJA0EpA6AAeArupQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKw+V5TCxC0LnzVEgqDbLKOq3nDvSEj6ehP0AAk6AJrMVQfFi8LvGfSIpJ83tDSGEI8A64lLi1fsqaH2aP016Xw/ZY2vHiieEb57lYDLL3cM9e5726lUYElu3xyUstj6CeinD3bKuhI2Ep7qwicctSEBItkMJHXXYJ/CshSv0PDopwacuHFo7GOaWP9HrV7Mh+7o/Cno9avZkP3dH4VkKiFr4uYjer23aod5Q7LdcU0ySy4ll9ad7S26UhtwjR6JUe41lVixTaKqrX7S86s/6PWr2ZD93R+FPR61ezIfu6PwqN2/jJh90uMaDGvAcfkyFRGlGM8lovgkFouFAQF7SdJJBPTQOxWE4tcdLNw/s1+ZhzmJGSQI3aoiLjuutIcI2hLq0DlQVeAUpJOxrvrVVtOHTTNc17o7S86p/6PWr2ZD93R+FcLxy0rQUKtkMpPeOwT+Fe5hZcZbWe9SQTr+ivuujNOpmnV6cSu87ApHa2NaG2FH98gv8ArMuj6AfnN/YU9N9SlXdWwmJ5VCzC0JnQyU6UW3mF/PZcABKFfbog/QQQR0IrXKpRwqvDlmz+LHBPm92bXGcT4dohCnG1f3JS4P8A5D6BXz/xPYaMbCqxqYtVTv746brE34r+pSlfChSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBWunEGMuFxHyFDg1262ZTex3oUyhG/t9dpwf3fZWxdQDirgT2TMR7nbUJVdoSSjsiQPOWSdqb34KBHMknpvY6cxUPY+FbRTs+0Xr3RVFu7p/C9imKV4Lpardk9tkW+5wmp8Nagh+HMZ2OZKgeVbah0UlQHQjYIqOp4NYGg7Th1jSdEbEBodCNHwr7yqa7/TEeP9MEhyK3vXfH7nBjvebyJUV1ht7/0KUggK/uJ3VHcL8SgLaxSyXvHM0YvNnLSnDLmS12th9hO0uoJd7IoJT6qUA65gNAbq1YPCXCrZNYmRMTs0aVHcS6081BbSttYOwpJA2CCN7qWVoqweUqiuuI3ff8Cg4uM3dHBaxwzapqZ7OWJlKj+bL7VDfyspfaFOthPIebm7uU77qxGVMXixYLxQxJeLXy4XS7zps2HOt8BchiU28oKQS4noFJT6pSevqjW+6tk6Vqq2SJi0VdFvtaw64wKYzQI0QgAg/wBFdlRS4cJsKus5+ZNxSzypb6y46+9CbUtxROyokjZJ+mulXBnA1nasOsajoDZgNdw6D+TXVfE6Ijx/pExrNYFFXO4iY60gE9i67Kc0PmoSytO/2loH99Ra12q24xbY9vtsJmBCQooYhw2eVPMpRPKhCR1JUT0A2SavThTgT2NsyLrc0BN1mJCAz0PmzI6hG/FRPrK106JHXl2eH4htNOz7PVm/yqiYiO/2Z06rBpSlfnYUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgjGUcN7BlzxkzYZbna5fPYqyy9odwUpOucDwCtgfRUVVwCt3cjIr2gb31MY/3bLNWjSu7D23acGnLRXNluqz9wGD+ct7/VF+BT9wGD+ct7/VF+BVp0rb8z2v8Ak9PYuqz9wGD+ct7/AFRfgU/cBg/nLe/1RfgVadKfM9r/AJPT2Lqs/cBg/nLe/wBUX4FfSeAVu7l5Fe1D7DGH/hmrRpT5ntf8noXRfF+G1gxJ4SYUMuzgCPPZbheeAI0eVSvmA+ISAD9FSilK4MTErxas2JMzPanEpSlawpSlApSlApSlApSlB//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTING QUESTION---\n",
      "---ROUTE TO VECTOR STORE----\n",
      "---RETRIEVE FROM VECTORSTORE---\n",
      "Node 'retrieve':\n",
      "{'question': 'Prompt Engineering', 'generation': AIMessage(content='Here are three questions based on the provided document content:\\n\\n1. What are the two most basic approaches for prompting a model in the context of autoregressive language models, as discussed in the document?\\n\\n2. According to the text, what are the potential biases that contribute to high variance in few-shot classification tasks with large language models (LLMs), as identified by Zhao et al. (2021)?\\n\\n3. What is the primary goal of prompt engineering, according to the document, and what is the main challenge in achieving this goal?', response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 2214, 'total_tokens': 2323, 'completion_time': 0.44356817, 'prompt_time': 0.569919525, 'queue_time': 0.015208591000000049, 'total_time': 1.013487695}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e1ca4bf-f96d-4d11-98a2-4390baf5cf39-0', usage_metadata={'input_tokens': 2214, 'output_tokens': 109, 'total_tokens': 2323})}\n"
     ]
    }
   ],
   "source": [
    "# # Step 7: Execute the workflow\n",
    "# inputs = {\n",
    "#     \"question\": \"Java\"\n",
    "# }\n",
    "# for output in app.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         print(f\"Node '{key}':\")\n",
    "#         print(value)\n",
    "\n",
    "# Example for querying ML topic\n",
    "inputs_ml = {\n",
    "    \"question\": \"Prompt Engineering\"\n",
    "}\n",
    "for output in app.stream(inputs_ml):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Node '{key}':\")\n",
    "        print(value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
