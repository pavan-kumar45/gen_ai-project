{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: cassio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.9.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cassio) (3.29.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio) (0.2.1.post1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (8.1.7)\n",
      "Requirement already satisfied: six in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.16.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langgraph cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2023.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: langchainhub in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: langchain in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: langchain_huggingface in c:\\users\\pavan\\anaconda3\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.115)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-groq) (0.11.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchainhub) (24.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchainhub) (2.32.0.20240905)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (2.9.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.113.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (3.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (6.4.4)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (0.24.6)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (3.0.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain_huggingface) (4.44.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.38.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.11.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.3.5)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pavan\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain_community tiktoken langchain-groq langchainhub chromadb langchain langgraph langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:DHXHpyDSDzDEJgnCEmpMvMhU:bcabbd14b419dce9d8617a4408d370ac37be10d33c26720664744cc7956012a0\"\n",
    "ASTRA_DB_ID = \"4d0ac63c-db4d-4461-a30b-5654bec200c2\"\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Step 1: Load and split documents\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\n",
    "]\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "# print(docs_list)\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=2000, chunk_overlap=500)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 3a85458f-9cdb-41f0-8a8c-3a472d3e5814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "# You can set the API key like this:\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-b5toQL69c8MZWasKLSTipIp6Rzrwf9rpYntsCKn5fnWZEg7X\"  # Your actual API key\n",
    "from llama_parse import LlamaParse\n",
    "pdf_path = r\"C:\\Users\\pavan\\Downloads\\GenAi.pdf\"\n",
    "documents = LlamaParse(result_type=\"text\", verbose=True).load_data(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='46ff5e7c-53e5-4009-9f8a-4316b9c934c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                           World Health\\n                           Organization\\n                                                                  FACT SHEET 1\\n\\n                                  What is Air Pollution?\\nWhat is air pollution?\\n\\n•    Air pollution is the contamination of the\\n     indoor or outdoor air by a range of\\n     gasses and solids that modify its\\n     natural characteristics. Key health-\\n     harmful pollutants include particulate\\n     matter (PM2.5 and PM10) 1 , carbon\\n     monoxide (CO), ozone (O3), black\\n     carbon      (BC),     sulfur     dioxide     and\\n     nitrogen oxides (NOx).\\n•    Air pollution is often not visible to the\\n     naked eye as the size of the pollutants\\n     are smaller than the human eye can\\n     detect.     They can become visible in\\n     some situations for example in the form\\n     of sooty smoke from the open burning\\n     of crop residues or other waste, as well\\n     as from burning wood, coal, petrol and\\n     diesel fuels for cooking and heating,\\n     transport or power production. The fact\\n     that you cannot see the air pollution\\n     does not mean that it does not exist.\\n\\nWhat are the most health\\nharmful air pollutants?\\n•    WHO has air quality guidelines for air\\n     pollutants which are regarded as the\\n     most harmful to health. These include\\n     ozone,      oxides     of    nitrogen,     sulfur\\n     dioxide, and carbon monoxide, as well\\n     as fine particulate matter.                 Fine\\n     particulate matter (PM 2.5) is the key\\n     indicator     used      in   making       health\\n     estimates of air pollution impacts and is\\n     most       commonly          measured          or\\n     monitored by governments around the\\n                                  Updated 11 November 2019\\n     world to protect citizens against the\\n     adverse impacts of air pollutants.\\n\\nWhat are the main health\\n\\nimpacts of particulate matter?\\n•    The health impacts of particulate matter\\n     depend on the level of exposure\\n     (frequently expressed in ug/m3) and\\n     the duration of exposure (which can be\\n     either short term e.g. 8 or 24 hours or\\n     long term e.g. annual)                Individual\\n     sensitivity to the health impacts of\\n     particulate matter can vary.\\n•    Short-term       exposure       to   particulate\\n     matter (or PM) is likely to cause acute\\n     health reactions such as irritation to the\\n     eyes, nose, and throat, coughing,\\n     wheezing and increased frequency of\\n     acute lower respiratory infections, deep\\n     in your lungs.\\n•    More       prolonged        and       continued\\n     exposure to either high or lower levels\\n     of air pollution can also lead to an\\n     increased risk of respiratory infections,\\n     exacerbation of asthma, bronchitis or\\n     serious      chronic       effects     including\\n     reduced lung function, ischaemic heart\\n     disease,      stroke,    lung     cancer      and\\n     premature death. Such symptoms are a\\n     particular concern in rural and peri-\\n     urban settings where use of wood,\\n     agricultural waste and animal dung is\\n     used for cooking, heating and lighting\\n     and exposure levels can be high and\\n     prolonged over long periods of time.\\n\\n\\n                  1 Particulate less than 2.5 micrometers and 10\\n                  micrometers respectively', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d06bf5e0-c4ad-49d4-9692-ba7ab624f7f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='What are the factors affecting a\\nnormally healthy person’s\\nvulnerability to air pollution?\\nPeople are more vulnerable to having\\nadverse health reactions to air pollution in\\nthe following situations:\\n•    Particularly high concentrations of\\n     particulate      matter.      A number of\\n     factors, including increased burning of\\n     fuel for winter, burning of agricultural\\n     crop residues, as well as particular\\n     weather patterns can all combine to\\n     create air pollution peaks.                High\\n     concentrations of particulate matter are\\n     more often found in winter-time when\\n     the temperature and wind affect the\\n     build-up     of   air    pollution     and     its\\n     persistence locally. Normally, when air\\n     gets colder, a layer of warm air traps a\\n     layer of cold air nearer the ground. This\\n     acts like a lid over a cloud of smog and\\n     stops it from rising and drifting away.\\n\\n•    Close        proximity       of      activities\\n     generating high levels of pollution\\n     including:\\n     o Heavy traffic on roads, vehicles not\\n          complying to pollution norms;\\n     o Thermal (coal-based) power plants\\n          and      other      factories      emitting\\n          polluting smoke;\\n     o Uncontrolled            construction         or\\n          demolition sites;\\n\\n     o Use of biomass fuel for domestic\\n          energy needs such as cooking;\\n\\n     o Bursting fire crackers;\\n     o Burning          waste      from     houses,\\n          hospitals, electronic waste, crop\\n          residues, etc.\\nWhat additional factors can\\naffect a person’s vulnerability?\\n\\n•   Age of person exposed: Children,\\n    especially under-five, and older people\\n    are particularly vulnerable.\\n•   Health status of person exposed.\\n    People, with pre-existing diseases such\\n    as     asthma      and     other     respiratory\\n    disease, cardiovascular diseases, are\\n    at greater risk of health effects.\\n•   Pregnant        women.        Evidence        has\\n    shown       that     pregnancy        increases\\n    vulnerability to the effects of particulate\\n    exposure with potential effects to the\\n    unborn child such as low and pre-term\\n    birth weight.\\n\\n•   Low socioeconomic status. Persons\\n    with low socioeconomic status with a\\n    pre-existing disease, poor nutritional\\n    status and poor housing conditions,\\n    including where household combustion\\n    of solid fuels takes place for cooking,\\n    heating or lighting. People living on the\\n    street     and     in   poor     housing      are\\n    particularly vulnerable.\\n•   Occupational exposures: Construction\\n    workers, traffic police, road sweepers\\n    and those working outdoors and in\\n    highly polluted settings.\\n\\n•   Smoking of tobacco products and\\n    exposure to second-hand smoke', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='iJRASET\n",
      "                            International Journal For Research in\n",
      "                            Applied Science and Engineering Technology\n",
      "           CH; 0\n",
      "                                              -100\n",
      "                                             50\n",
      " 45\n",
      "INTERNATIONAL JOURNAL\n",
      "             FOR RESEARCH\n",
      "     IN APPLIED SCIENCE & ENGINEERING TECHNOLOGY\n",
      " Volume:        Issue:       Month of publication:\n",
      " DOI:\n",
      "                    wwW.ijraset.com\n",
      "Call:    08813907089           E-mail ID: ijraset@gmail.com\n",
      "               12              V                                   May 2024\n",
      "\n",
      "           https://doi.org/10.22214/ijraset.2024.62488'\n",
      "page_content='({Research I /Applied} Scicnce / 0 International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                  Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "\n",
      "              Question Paper Checking Using Generative Ai\n",
      "                               Divekar Nikhil1, Kakade Komal, Karale Sumit3, Pandarkar Sakshi, Prof. Bhosale S. S.52                             4\n",
      "                                           Department of Computer Engineering, HSBPVT’s Faculty of Engineering, Kashti'\n",
      "page_content='Abstract: In the present era, the world is moving towards computerization. Everything is made easy so, automatic answer sheet\n",
      "    checker is required. Checking the answer sheet manually takes a lot of time and energy. The application in this project is based\n",
      "    on verification or evaluation of answer sheet using ML and AI. The main objective of this project will be to save time and\n",
      "    manpower. An automated answer checker app that checks and marks answers just like a human. This software application is\n",
      "    designed to check the answers in the exam and allocate marks to the students after verifying the answers. The system requires\n",
      "    teachers to store the original answer for the system. This facility is provided to teachers. Teachers can enter questions and\n",
      "    related subjective answers into the system. These responses are stored as database files. The first answer is captured in PDF\n",
      "    form and then compares this answer with the original answer written in the database and allocates marks accordingly. The total\n",
      "    marks are calculated and the result is finally shown. The system allocates marks according to how good a student is.\n",
      "    Keywords: Automatic Answer Checker, ML, AI, Java, My SQL, Hibernate, Spring Boot, Keyword Matching Algorithm,\n",
      "    Levenshtein Distance Algorithm.\n",
      "                                                                                    I.            INTRODUCTION\n",
      "    There are many ways of conducting exams in today's world. Every day, various examinations are carried out all over the world. The\n",
      "    most important aspect of any exam is checking the student's answer sheet. This is usually done by the teacher manually, so it is very\n",
      "    tedious work if the number of students is very large. Traditional methods of marking and grading written questions can be time-\n",
      "    consuming, error-prone, and subject to bias. In such a case, automating the response checking process would definitely prove to be\n",
      "    very useful. Automating the answer checking process would not only make it easier for the examiner but the checking process\n",
      "    would also become much more transparent and fair as there would be no possibility of bias on the part of the teacher. Currently,\n",
      "    there are various online tools available for reviewing multiple choice questions, but there are very few tools for reviewing long\n",
      "    answer type exams. This project aims to review long answer type exams by implementing machine learning and artificial\n",
      "    intelligence. This application can be used in various educational institutions to check subjective answer type exams. This project\n",
      "    aims to change the assessment process, making it more efficient, accurate and unbiased.'\n",
      "page_content='II.            LITERATURE REVIEW\n",
      "    A. An online system for verifying subjective answers using artificial intelligence:\n",
      "    1) Online Subjective Answer Verification System Using AI:\n",
      "    Authors: Jagadamba G, Chaya Shree G.\n",
      "    Organizations/Educational Institutes are always dependent on the system of evaluation through examinations. However,                                                                   most\n",
      "    examinations are objective. These systems or any other                                     such system is preferable in terms of saving resources but it                       has failed\n",
      "    include subjective questions. This article attempted to evaluate the descriptive response. The evaluation is done by means of a grap\n",
      "    hical comparison with the standard response.\n",
      "\n",
      "    2) Evaluating Subjective Responses using Machine Learning and Natural Language Processing (2021)\n",
      "    Authors: Hamza Arshad, Abdul Rehman Javed.\n",
      "    In the past, various methods were used for the subjective evaluation of answers and their shortcomings were observed. In this paper,\n",
      "    we propose a new approach to solve this problem, which is to train a machine learning classification model using the results obtaine\n",
      "    d from our result prediction module, and then use our trained model to reinforce the results from the prediction model, which can lea\n",
      "    d to a fully trained machine learning.\n",
      "\n",
      "    3) Automatic Response Check\n",
      "    Authors: Vasu Bansal, M.L. Sharma,Krishna Chandra Tripathi\n",
      "    The proposed system could be very useful for educators whenever they need to conduct a quick test for revision purposes as                                                            it sav\n",
      "    es time and effort to evaluate the packet documents. This system would be beneficial for universities, schools and colleges for acade\n",
      "    mic purposes by providing ease faculties and examination assessment cell.\n",
      "\n",
      "       ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                                            4362'\n",
      "page_content='({Research I /Applied} Scicnce / 0   International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                      Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "                                                                                    III.           EXISTING SYSTEM\n",
      "    Human graders may introduce bias or subjectivity into the grading process. Different graders may assign different scores for the\n",
      "    same answer based on their personal interpretation or preferences. Manual grading is time-consuming, especially for subjective\n",
      "    questions or open-ended responses. It requires significant manpower and resources, which can slow down the feedback process for\n",
      "    students.\n",
      "                                                                                   IV.           PROPOSED SYSTEM\n",
      "    An automatic answer sheet checking system is a software that can evaluate and grade answer sheets from exams without the need\n",
      "    for a human to do it manually. Answers written on the paper, comparing them to the correct answers, and then assigning a score to\n",
      "    each question or the entire test.\n",
      "    This system can save time and reduce the potential for human error in the grading process.'\n",
      "page_content='V.             WORKING OF PROJECT\n",
      "    An automatic answer checker is an application that helps in checking the answer sheets submitted by the student in a similar manner\n",
      "    as a human being. This application has been built with an aim to check the long answer type questions and then allot marks to the\n",
      "    students after performing the verification of the answers. To carry out the whole operation, it is required by the user to store the\n",
      "    answers of the questions so that the application can cross verify the answers from the answer sheet.\n",
      "                                                                     Answer Sheets                     Scanning &                     Data Inputs\n",
      "                                                                                                       Dgitization\n",
      "                                                                     Question Mapping                Scoring Criteria               Machine Learning\n",
      "                                                                                                                                    Models\n",
      "                                                                        Scoring                     Report Generate                   Data Storage &\n",
      "                                                                                                                                      Analysis'\n",
      "page_content='Fig. Working of Project'\n",
      "page_content='Answer sheets are collected and digitized. The AI system processes the data, mapping answers to questions. Scoring criteria is used\n",
      "    to understand and evaluate responses. Machine learning models assign scores based on criteria. Scores are generated. Reports are\n",
      "    generated and data is stored for analysis.\n",
      "    The AI system learns and improves over time.\n",
      "    The process of checking answer sheets using generative AI involves the following steps:\n",
      "    1)      Data Collection: Gather a large dataset of annotated answer sheets, including both correct and incorrect answers. This dataset is\n",
      "            used to train the generative AI model.\n",
      "    2)      Model Training: Train a generative AI model, such as a language model, using the collected dataset. The model learns to\n",
      "            generate answers based on the patterns and information in the training data.\n",
      "    3)      Answer Generation: When an answer sheet is submitted for checking, the generative AI model takes the questions and answers\n",
      "            as input and generates a response. It can also provide explanations for its generated answers.\n",
      "    4)      Comparison: The generated answers are compared to the expected correct answers. This step may involve natural language\n",
      "            processing techniques to assess the similarity and correctness of the generated responses.\n",
      "    5)      Evaluation: The system evaluates the accuracy of the generated answers and assigns a score based on how well they match the\n",
      "            correct answers. Additionally, it can provide feedback on the student's performance.\n",
      "    6)      Continuous Improvement: The generative AI model can be fine-tuned and improved over time with additional data and\n",
      "            feedback from educators to enhance its accuracy and effectiveness.\n",
      "\n",
      "                                                                                        VI.           TECHNOLOGY\n",
      "    1)      HTML, CSS, JS\n",
      "    2)      Java\n",
      "    3)      My SQL\n",
      "    4)      Hibernate Framework\n",
      "    5)      Spring Boot\n",
      "\n",
      "       ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                               4363'\n",
      "page_content='({Research I /Applied} Scicnce / 0  International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                    Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "                                                                                        VII.          ALGORITHM\n",
      "    A. Heuristic Rule Based Algorithm\n",
      "    A heuristic rule-based algorithm is used to calculate the similarity between two texts.\n",
      "    Working Steps:-\n",
      "    Text Extraction: Uses Mammoth.js to extract raw text from .docx files.\n",
      "    Text Reading: Reads the extracted text using FileReader.\n",
      "    Text Comparison: Splits the model and student answers into words and sentences.\n",
      "    Keyword Matching: Counts the number of words in the model answer that also appear in the student answer.\n",
      "    Sentence Matching: Counts the number of sentences in the model answer that also appear in the student answer.\n",
      "    Meaningful Sentence Matching: Counts the number of sentences in the model answer that also appear in the student answer.\n",
      "    Percentage Calculation: Calculates the total percentage of matches relative to the length of the model answer.\n",
      "\n",
      "    B. Comparison Algorithm\n",
      "    Comparison algorithm is used to calculate the similarity percentage between the model answer and the student's answer.\n",
      "    Working Steps\n",
      "    1)     Keyword Matching: The model answer and the student's answer are split into individual words. It counts how many words from\n",
      "           the model answer are present in the student's answer. This counts as a keyword match.\n",
      "    2)     Sentence Matching: Both the model answer and the student's answer are split into sentences. It counts how many sentences\n",
      "           from the model answer are present in the student's answer. This counts as a sentence match.\n",
      "    3)     Meaningful Sentence Matching: Similar to sentence matching. It counts how many meaningful sentences from the model\n",
      "           answer are present in the student's answer. This counts as a meaningful sentence match.\n",
      "    4)     Total Matches Calculation: It sums up the counts from keyword matching, sentence matching, and meaningful sentence\n",
      "           matching to get the total number of matches between the model answer and the student's answer.\n",
      "    5)     Percentage Calculation: It divides the total number of matches by the sum of the total number of keywords and total number of\n",
      "           sentences in the model answer. The result is multiplied by 100 to get a percentage. The percentage is capped at 100%.\n",
      "    6)     Result: The calculated percentage indicates the similarity between the model answer and the student's answer. If the similarity\n",
      "           percentage is greater than or equal to 35%, it's considered a pass. Otherwise, it's considered a fail. This comparison algorithm\n",
      "           provides a basic measure of similarity between the two answers, taking into account both word-level and sentence-level\n",
      "           matches while filtering out shorter, potentially less significant sentences.'\n",
      "page_content='VIII.          MATHEMATICAL MODELS\n",
      "    A. Keyword Matching\n",
      "    Description: This involves splitting the text into individual words and checking how many of these words in the student's answer\n",
      "    match the words in the model answer.\n",
      "\n",
      "    1)     Mathematical Model\n",
      "    Set Intersection: The number of common words (keywords) between the model answer and the student answer.\n",
      "\n",
      "    2)     Given\n",
      "    ܯM as the set of words in the model answer.\n",
      "    ܵ S as the set of words in the student answer.\n",
      "    The number of matching keywords is calculated as:\n",
      "    keyword_matches=∣M∩S∣\n",
      "\n",
      "    B. Sentence Matching\n",
      "    Description: This involves splitting the text into sentences and checking how many sentences in the student's answer match exactly\n",
      "    with the sentences in the model answer.\n",
      "\n",
      "    1)     Mathematical Model\n",
      "    Set Intersection: The number of common sentences between the model answer and the student answer.\n",
      "\n",
      "       ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                              4364'\n",
      "page_content='({Research I /Applied} Scicnce / 0 International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                  Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "    2) Given\n",
      "    ܯM as the set of sentences in the model answer.\n",
      "    ܵ S as the set of sentences in the student answer.\n",
      "    The number of matching sentences is calculated as:\n",
      "    sentence_matches=∣M∩S∣\n",
      "\n",
      "    3) Meaningful Sentence Matching\n",
      "    Description: This involves identifying sentences and checking how many such meaningful sentences match between the student's\n",
      "    answer and the model answer.\n",
      "\n",
      "    a) Mathematical Model\n",
      "    Set Intersection with Length Filter: The number of common meaningful sentences between the model answer and the student\n",
      "    answer.\n",
      "\n",
      "    b) Given\n",
      "    ܯM as the set of meaningful sentences in the model answer.\n",
      "    ܵ S as the set of meaningful sentences in the student answer.\n",
      "    The number of matching meaningful sentences is calculated as:\n",
      "    meaningful_sentence_matches=∣ܯ∩ܵ ∣\n",
      "\n",
      "    4) Total Similarity Score Calculation\n",
      "    Description: The script combines the matches from the above three metrics to compute a total similarity score, normalizing it to a\n",
      "    percentage.\n",
      "\n",
      "    a) Mathematical Model\n",
      "    Combined Score: The total matches are computed by summing the keyword matches, sentence matches, and meaningful sentence\n",
      "    matches. The total percentage is calculated by normalizing this combined score.\n",
      "\n",
      "    b) Given\n",
      "    ܭK as the number of keywords in the model answer.\n",
      "    ܵ S as the number of sentences in the model answer.\n",
      "    The total matches are:\n",
      "    total_matches=keyword_matches+sentence_matches+meaningful_sentence_matchestotal_matches=keyword_matches+sentence_ma\n",
      "    tches+meaningful_sentence_matches\n",
      "    The total percentage is:\n",
      "    total_percentage=(total_matchesܭ+ܵ )×100\n",
      "\n",
      "                                                      IX.           TEXT-TO-TEXT GENERATIVE AI TRANSFORMER\n",
      "    A. HTML Structure\n",
      "    The code snippet itself is JavaScript, but it's designed to work with an HTML structure that includes elements like file input fields\n",
      "    for uploading model and student answer files, buttons for actions like submitting, and elements to display processing messages and\n",
      "    results.\n",
      "\n",
      "    1) checkPapers() Function\n",
      "    This function is triggered when the user clicks a button to check papers. It retrieves the uploaded model and student answer files\n",
      "    from the HTML input fields. If both files are uploaded (modelAnswerFile and studentAnswerFile), it hides certain elements (like\n",
      "    the file upload fields and submit button), displays a processing message, and then calls the readAndCheckPapers() function after a\n",
      "    delay of 2000 milliseconds (2 seconds).'\n",
      "page_content='©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                             4365'\n",
      "page_content='({Research I /Applied} Scicnce / 0 International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                   Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "    2) readAndCheckPapers() Function:\n",
      "    This function reads the contents of the model answer and student answer files using the FileReader API.\n",
      "    When the contents are loaded (onload event), it extracts the text from both files.\n",
      "    It then calls the calculatePercentage() function to compare the model answer with the student answer and determine the similarity\n",
      "    percentage.\n",
      "    After calculating the percentage, it updates the UI to display the result and messages indicating whether the student passed or failed\n",
      "    based on the similarity percentage.\n",
      "\n",
      "    3) calculatePercentage() Function:\n",
      "    This function calculates the similarity percentage between the model answer and the student answer.\n",
      "    It splits both answers into keywords, sentences, and meaningful sentences. It then counts the matches between the model answer and\n",
      "    the student answer at these different levels (keywords, sentences, and meaningful sentences).\n",
      "    The total number of matches is divided by the total number of keywords and sentences in the model answer to calculate the\n",
      "    percentage. The calculated percentage is capped at 100% and returned as a string with two decimal places.\n",
      "\n",
      "    B. External Library Usage\n",
      "    The code uses an external library called \"Mammoth\" (mammoth.browser.min.js) to extract raw text from uploaded files.\n",
      "    It utilizes the mammoth.extractRawText() function to extract text from the uploaded files asynchronously. Once the text is\n",
      "    extracted, it's passed to the respective FileReader for further processing.'\n",
      "page_content='X.            TRADITIONAL SYSTEM VS AUTOMATED SYSTEM\n",
      "                                                                 12                                    Comparison\n",
      "                                                                                                                               Traditional Method\n",
      "                                                                                                                               Automated Method\n",
      "                                                              1 0 6\n",
      "                                                                  03\n",
      "                                                                              Recall             Precision          kcuracy             F-Measure\n",
      "                                       Fig. The Performance Analysis Between Traditional Approach & Automated Approach.\n",
      "\n",
      "                                                                                            XI.           RESULT'\n",
      "page_content='Sr.       Project Name                           Accuracy              No. of Paper\n",
      "                                                             No.                                                                    Checked\n",
      "                                                             1         Question Paper                         90-95%                500\n",
      "                                                                       Checking Using\n",
      "                                                                       Generative AI\n",
      "                                                             2         BERT-based Answer                      85-90%                450\n",
      "                                                                       Checking\n",
      "                                                             3         Transformer-based                      80-85%                480\n",
      "                                                                       Answer Checking\n",
      "\n",
      "       ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                             4366'\n",
      "page_content='({Research I /Applied} Scicnce / 0 International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                  Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "                                                                                      XII.          ADVANTAGES\n",
      "    1) Time Efficiency: AI-based systems can quickly analyze and evaluate a large volume of answer sheets, significantly reducing the\n",
      "           time required for grading compared to manual assessment.\n",
      "    2) Immediate Feedback: AI-powered systems can offer immediate feedback to students, enabling them to identify their mistakes\n",
      "           and areas for improvement promptly, facilitating a more dynamic learning process.\n",
      "    3) Reduced Workload for Educators: Automating the grading process can alleviate the burden on educators, allowing them to\n",
      "           focus more on developing innovative teaching methodologies and providing personalized guidance to students.\n",
      "    4) Cost-Effectiveness: While the initial investment in implementing AI systems might be substantial, the long-term cost savings\n",
      "           resulting from reduced manual grading and increased efficiency can be significant for educational institutions.\n",
      "\n",
      "                                                                                     XIII.         APPLICATIONS\n",
      "    1) Government Organization\n",
      "    2) Colleges\n",
      "    3) Schools'\n",
      "page_content='XIV.          IMPLEMENTATION\n",
      "    1) Login Page\n",
      "                                                                                                    Studtnt Looin\n",
      "    2) Examination Paper Checking\n",
      "                                                                                                            Paper Checking\n",
      "    3) Student Score\n",
      "                                                                                                  Check Student Scote\n",
      "       ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                             4367'\n",
      "page_content='({Research I /Applied} Scicnce / 0      International Journal for Research in Applied Science & Engineering Technology (IJRAISSN: 2321-9653; IC Value: 45.98; SJ Impact Factor: 7.538)\n",
      "                                                                                                                                Volume 12 Issue V May 2024- Available at www.ijraset.com\n",
      "                                                                                                  XV.            CONCLUSION\n",
      "     We concluded that while generative AI can offer various applications in the context of question paper checking, it is important to\n",
      "     recognize its limitations and use it as a complementary tool rather than a complete substitute for human judgment. Its potential lies\n",
      "     in automating routine tasks, providing standardized assessments, detecting plagiarism, and offering personalized feedback to\n",
      "     students. However, it may struggle with subjective evaluations, lack contextual understanding, and exhibit biases present in the\n",
      "     training data. Integrating generative AI into the education system can enhance efficiency, provide valuable insights, and support\n",
      "     educators in offering a more personalized learning experience. Yet, the role of human expertise remains indispensable in ensuring\n",
      "     fairness, contextual understanding, and holistic evaluation, emphasizing the importance of a balanced approach that combines the\n",
      "     strengths of both AI and human educators.'\n",
      "page_content='REFERENCES\n",
      "     [1]     Vishwas Tanwar, Machine Learning based Automatic Answer Checker Imitating Human Way of Answer Checking, International Journal of Engineering\n",
      "             Research & Technology (IJERT) ISSN: 2278-0181 Vol. 10 Issue 12, December-2021.\n",
      "     [2]     Ronika Shrestha, Raj Gupta, Priya Kumari, Automatic AnswerSheet Checker.\n",
      "     [3]     Prof. Priyadarshani Doke, Priyanka Gangane, Kesia S Babu, Pratiksha Lagad, Neha Vaidya, Online Subjective Answer Verifying System Using Artificial\n",
      "             Intelligence, Ijraset Journal for Research in Applied Science and Engineering Technology.\n",
      "     [4]     Yang-Yen Ou∗, Shu-Wei Chuang, Wei-Chun Wang, and Jhing-Fa Wang Automatic Multimedia-based Question-Answer Pairs Generation in Computer\n",
      "             Assisted Healthy Education System 2022 10th International Conference on Orange Technology (ICOT).\n",
      "     [5]     Jinmeng Wu, Fulin Ge, Pengcheng Sh, Lei Ma, Yanbin Hao Question-Driven Multiple Attention (DQMA) Model for Visual Question Answer 2022\n",
      "             International Conference on Artificial Intelligence and Computer Information Technology (AICIT).\n",
      "     [6]     S.Lakshmipriya, Automatic Answer Checker, IJSRD - International Journal for Scientific Research & Development| Vol. 8, Issue 3, 2020.\n",
      "     [7]     S.Nahida, Automatic Answer Evaluation Using Machine Learning, Dogo Rangsang Research Journal, Issn : 2347-7180\n",
      "     [8]     Piyush Patil, Sachin Patil, Vaibhav Miniyar ,Amol Bandal, Subjective Answer Evaluation Using Machine Learning, International Journal of Pure and Applied\n",
      "             Mathematics\n",
      "     [9]     Merien Mathew, Ankit Chavan, Siddharth Baikar, Online Subjective Answer Checker, International Journal of Scientific & Engineering Research.\n",
      "     [10] Vasu Bansal, M. L. Sharma, Krishna Chandra Tripathi, Automated Answer-Checker, International Journal for Modern Trends in Science and Technology.\n",
      "\n",
      "        ©IJRASET: All Rights are Reserved | SJ Impact Factor 7.538 | ISRA Journal Impact Factor 7.894 |                                                                                   4368'\n",
      "page_content='doi                                                     SRA                                             8\n",
      " cross ref                   INDEX                  J     F                                             @\n",
      "                         COPERNICUS                                         TOGETIIER WE REACHTHE GOAL   1S1 ISI\n",
      "10.22214/IJRASET               45.98              IMPACT FACTOR:             IMPACT FACTOR:\n",
      "                                                         7.129                      7.429\n",
      "             INTERNATIONAL JOURNALFOR RESEARCH\n",
      "                     IN APPLIED SCIENCE & ENGINEERING TECHNOLOGY\n",
      "             Call      08813907089                    (24*7 Support on Whatsapp)'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document  # Use this to create Document objects\n",
    "\n",
    "# First, extract text from the documents parsed by LlamaParse\n",
    "# Assuming documents is a list of text content, convert each entry to a Document\n",
    "\n",
    "document_objects = [Document(page_content=doc.get_content()) for doc in documents]\n",
    "\n",
    "# Now, use RecursiveCharacterTextSplitter to split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(document_objects)\n",
    "\n",
    "# Now you have the PDF content split into chunks\n",
    "# You can print or process it further\n",
    "for split in doc_splits:\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavan\\anaconda3\\Lib\\re\\__init__.py:361: RuntimeWarning: coroutine 'LlamaParse.aload_data' was never awaited\n",
      "  m = match()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['76a34e78bfb348f38c505348a6b7af99',\n",
       " 'a91f8351735e4316a177ae8713772f20',\n",
       " '56024dec893943fdbf0ab4834ce301a0',\n",
       " 'b86d85e50fa946399d7f14a41d378ef4',\n",
       " 'e526ad80b1364824b917054698b0313d',\n",
       " '2de7e48b107c431dbcc9dbc187412388',\n",
       " 'b8ccbe7da099417ab78d7244f7b32ba8',\n",
       " '73554bda76ca4a339e6991e594a856ea',\n",
       " '702f9c25cab24dfd87544ad8a0931de9',\n",
       " 'fe6695e98162428ab4410d49759153f0',\n",
       " 'd571b3281a4e4c1dbacfe9cfffc8b8f9',\n",
       " 'b3e0c03e05d4490499b95eb8b3a17372',\n",
       " 'd1fe91cbaca34f3faea2866eec0de5c8',\n",
       " 'ab284f97eb2544bb859ed6d3209243ea',\n",
       " 'b2fcdc4ab7b041c6bdec8d93c0b40c57',\n",
       " '9fffee54c8a842a998d6b80bf2c5c610',\n",
       " 'a03a1095b39249e785dddc125f2b4da4',\n",
       " 'f48064bc4f51447ebda4eb45d77b0369',\n",
       " '077a2c03b95f486a9aafc8b4019d98bf',\n",
       " 'b779e969aa9e407fa87517c405eb776e']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Store embeddings in AstraDB\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "astra_vector_store = Cassandra(embedding=embeddings, table_name=\"demo6\")\n",
    "astra_vector_store.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P. Babakhani et al.: Opinerium: Subjective Question Generation Using Large Language Models\n",
      "                                                                   flan-TS-small                                                     flan-TS-base                                                                 flan-T5-large\n",
      "                              Human          1.00              0 04     0.03      0.15              0.04          1.00           0.04     oloo                        001       0.18                 0.01     0.01     20 03                 loq\n",
      "                                BLEU        0.06      1.00     0.83     0.87                              0 10                   0,83     0.88               0.12               0.20                 1.00     0.84     0.88      0.33  0.05  U,UU      0.10             0.75\n",
      "                             ROUCE           0.04     0,83     1,00     0,86      0,12              0,07  010     0,04  0 83              0,87      0,32     0,10               018        0,01     0 84      1,00     0 86      0,31  0,10            0,06\n",
      "\n",
      "1) FLAN-T5                                                                                                                                                                           B. EVALUATION\n",
      "                                            We have fine-tuned the flan-T5 variants [25] on a Tesla                                                                                                                             Evaluating a question based on a textual source encompasses\n",
      "                                            P100-16GB GPU machine. The flan-T5 small, base and large                                                                                                                            various factors, including semantic connection, the potential\n",
      "                                            models1 have been obtained from the Hugging Face [44]                                                                                                                               for a response, pertinence, and grammatical construction.\n",
      "                          METEOR            0,03      0,87     0, 86    1,00      0.,10             0,09  0,08   0,00   0 88     0,87      1,00     0,30              002       014                 0 88      0 86      1,00     0,32  0.14  '0i02     0,07\n",
      "                                                                                                                                                                                                                                                                        0 50\n",
      "                        BERTScore           0.15      0.11                        1,00     0 52     0,17          016   0.32     0,32     0,30      1,00              011       0.18       0,16     0,.33               0 32     100   043   0,12      0,16\n",
      "                            BLEURT          0,31               0.15              052                0,34  0 20                                               100      0417     0,30                                                          0,06\n",
      "                           QAScore\n",
      "                            RQUGE                     0.10     0.10\n",
      "defined as:                                                                                                                                                                         evaluations.Classically, ROUGE, BLEU, and METEOR are employed\n",
      "                                                                                                              1  ∑∑log P (q|q1, q2, . . . , qj−1, C; θ) ,\n"
     ]
    }
   ],
   "source": [
    "# Assuming you want to retrieve the top N results\n",
    " # Set this to the number of top results you want\n",
    "\n",
    "retriever = astra_vector_store.as_retriever()\n",
    "\n",
    "# Modify the invoke method to include a parameter for the number of top results\n",
    "results = retriever.invoke(\"ABSTRACT\", ConsistencyLevel=\"LOCAL_ONE\")\n",
    "\n",
    "retrieved_content = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "# print(retrieved_content)\n",
    "\n",
    "from collections import OrderedDict \n",
    "\n",
    "def remove_duplicates(text):\n",
    "    # Split the text into lines and remove duplicate lines\n",
    "    lines = text.split('\\n')\n",
    "    unique_lines = list(OrderedDict.fromkeys(lines))  # Preserve the order and remove duplicates\n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "cleaned_text = remove_duplicates(retrieved_content)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: \"The provided context does not explicitly state a conclusion. However, it appears to be a description of a system for checking the similarity between a model answer and a student's answer, using various mathematical models and algorithms. The text explains the different components of the system, including keyword matching, sentence matching, and meaningful sentence matching, as well as the calculation of a total similarity score. It also describes the code structure and functionality, including the use of an external library called \"Mammoth\" for text extraction.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-70b-versatile\")\n",
    "answer = astra_vector_index.query(\"What is the Conclustion ?\", llm=llm).strip()\n",
    "print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 0}, page_content='FACT SHEET 1  \\nWhat is Air Pollution? \\nWhat is air pollution? \\n\\uf0b7Air pollution is the contamination of the\\nindoor or outdoor air by a range of\\ngasses and solids that modify its\\nnatural characteristics. Key health-\\nharmful pollutants include particulate\\nmatter (PM2.5 and PM10) 1, carbon\\nmonoxide (CO), ozone (O3), black\\ncarbon (BC), sulfur dioxide and\\nnitrogen oxides (NOx).\\n\\uf0b7Air pollution is often not visible to the\\nnaked eye as the size of the pollutants\\nare smaller than the human eye can\\ndetect.  T hey can become visible in\\nsome situations for example in the form\\nof sooty smoke  from the open burning\\nof crop residues or other waste, as well\\nas from burning wood, coal, petrol and\\ndiesel fuels for cooking and heating,\\ntransport or power production.   The fact\\nthat you cannot see the air pollution\\ndoes not mean that it does not exist.\\nWhat are the most health \\nharmful air pollutants? \\n\\uf0b7WHO has air quality guidelines for air\\npollutants which are regarded as the\\nmost harmful to health.   These include\\nozone, oxides of nitrogen, sulfur\\ndioxide, and carbon monoxide, as well\\nas fine particulate matter.  Fine\\nparticulate matter (PM 2.5) is the key\\nindicator used in making health\\nestimates of air pollution impacts and is\\nmost commonly measured or\\nmonitored by governments around the\\n1 Particulate less than 2.5 micrometers and 10 \\nmicrometers respectively world to protect citizens against the \\nadverse impacts of air pollutants.  \\nWha t are the main health \\nimpacts of particulate matter ? \\n\\uf0b7The health impacts of particulate matter\\ndepend on the level of exposure\\n(frequently expressed in ug/m3) and\\nthe duration of exposure (which can be\\neither short term  e.g. 8 or 24 hours or\\nlong term e.g. annual)  Individual\\nsensitivity to the health impacts of\\nparticulate matter can vary.\\n\\uf0b7Short-term exposure to particulate'), Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 0}, page_content='matter (or PM) is likely to cause acute\\nhealth reactions such as irritation to the\\neyes, nose, and throat, coughing,\\nwheezing and increased frequency of\\nacute lower respiratory infections, deep\\nin your lungs.\\n\\uf0b7More prolonged and continued\\nexposure to either high or lower levels\\nof air pollution can also lead to an\\nincreased risk of respiratory infections ,\\nexacerbation of asthma, bronchitis or\\nserious chronic effects including\\nreduced lung function, ischaemic heart\\ndisease, stroke , lung cancer  and\\npremature death . Such symptoms are a\\nparticular concern in rural and peri-\\nurban settings where use of wood,\\nagricultural waste and animal dung is\\nused for cooking, heating and lighting\\nand exposure levels can be high and\\nprolonged over long periods of time.Updated  11 November 2019'), Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 1}, page_content='What are the factors affecting a \\nnormally  healthy person’s \\nvulnerability  to air pollution?  \\nPeople are more vulnerable to having \\nadverse health reactions to air pollution in \\nthe following situations :   \\n\\uf0b7 Particularly high c oncentration s of \\nparticulate matter . A number of \\nfactors, including  increased burning  of \\nfuel for winter, burning  of agricultural \\ncrop residues , as well as particular  \\nweather  patterns can all combine to \\ncreate air pollution peaks.  High \\nconcentrations of particulate matter are \\nmore often found in winter -time when \\nthe temperature and wi nd affect the \\nbuild -up of air pollution and its \\npersistence locally.  Normally, when air \\ngets colder, a layer of warm  air traps a \\nlayer of cold air nearer the ground. This \\nacts like a lid over a cloud of smog and \\nstops it from rising and drifting away .  \\n\\uf0b7 Close proximity  of activities \\ngenerating high levels of pollution \\nincluding:  \\no Heavy traffic on roads, vehicles not \\ncomplying to pollution norms;  \\no Thermal (coal-based ) power plants \\nand other factories emitting \\npolluting smoke;  \\no Uncontrolled construction or \\ndemolition sites;  \\no Use of biomass fuel for domestic \\nenergy needs  such as cooking ; \\no Bursting fire crackers;  o Burning waste from houses, \\nhospitals, electronic waste, crop \\nresidues , etc.  \\nWhat additional factors can \\naffect a person’s vulnerability ?  \\n\\uf0b7 Age of person  exposed : Children,  \\nespecially under -five, and older people \\nare particularly vulnerable.  \\n\\uf0b7 Health status of person exposed .  \\nPeople , with pre -existing diseases such \\nas asthma and other respiratory \\ndisease , cardiovascular diseases , are \\nat greater risk of heal th effects.   \\n\\uf0b7 Pregnant women . Evidence has \\nshown that pregnancy increases \\nvulnerability to the effects of particulate \\nexposure with potential effects to the'), Document(metadata={'source': 'C:\\\\Users\\\\pavan\\\\Downloads\\\\what-is-air-pollution-2019.pdf', 'page': 1}, page_content='unborn child such as low and pre -term \\nbirth weight . \\n\\uf0b7 Low socioeconomic status . Persons \\nwith low soci oeconomic status with a \\npre-existing disease,  poor nutritional \\nstatus  and poor housing conditions, \\nincluding where household combustion \\nof solid fuels takes place for cooking, \\nheating or lighting.  People living on the \\nstreet and in poor hous ing are \\nparticularly vulnerable.  \\n\\uf0b7 Occupational  exposures : Construction  \\nworkers, traffic police , road sweepers \\nand those working outdoors and in \\nhighly polluted settings . \\n\\uf0b7 Smoking of tobacco products  and \\nexposure to second -hand smoke')]\n"
     ]
    }
   ],
   "source": [
    "# !pip install pypdf\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Step 1: Load and split PDF documents\n",
    "pdf_path = r\"C:\\Users\\pavan\\Downloads\\what-is-air-pollution-2019.pdf\"  # Replace with the path to your PDF\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Now you have the PDF content split into chunks\n",
    "# You can print or process it further\n",
    "print(doc_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate embeddings using HuggingFace model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a3a37e72511a4bcd918a5e12cbaa6524',\n",
       " '1ecd7852d75741c8b2981e597be2757b',\n",
       " 'f54cb88b97a548588eaf846a24b9fae7',\n",
       " '9abe1896566f4b99a8ab2a20f3b3eedb']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Store embeddings in AstraDB\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "astra_vector_store = Cassandra(embedding=embeddings, table_name=\"demo2\")\n",
    "astra_vector_store.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FACT SHEET 1  \\nWhat is Air Pollution? \\nWhat is air pollution? \\n\\uf0b7Air pollution is the contamination of the\\nindoor or outdoor air by a range of\\ngasses and solids that modify its\\nnatural characteristics. Key health-\\nharmful pollutants include particulate\\nmatter (PM2.5 and PM10) 1, carbon\\nmonoxide (CO), ozone (O3), black\\ncarbon (BC), sulfur dioxide and\\nnitrogen oxides (NOx).\\n\\uf0b7Air pollution is often not visible to the\\nnaked eye as the size of the pollutants\\nare smaller than the human eye can\\ndetect.  T hey can become visible in\\nsome situations for example in the form\\nof sooty smoke  from the open burning\\nof crop residues or other waste, as well\\nas from burning wood, coal, petrol and\\ndiesel fuels for cooking and heating,\\ntransport or power production.   The fact\\nthat you cannot see the air pollution\\ndoes not mean that it does not exist.\\nWhat are the most health \\nharmful air pollutants? \\n\\uf0b7WHO has air quality guidelines for air\\npollutants which are regarded as the\\nmost harmful to health.   These include\\nozone, oxides of nitrogen, sulfur\\ndioxide, and carbon monoxide, as well\\nas fine particulate matter.  Fine\\nparticulate matter (PM 2.5) is the key\\nindicator used in making health\\nestimates of air pollution impacts and is\\nmost commonly measured or\\nmonitored by governments around the\\n1 Particulate less than 2.5 micrometers and 10 \\nmicrometers respectively world to protect citizens against the \\nadverse impacts of air pollutants.  \\nWha t are the main health \\nimpacts of particulate matter ? \\n\\uf0b7The health impacts of particulate matter\\ndepend on the level of exposure\\n(frequently expressed in ug/m3) and\\nthe duration of exposure (which can be\\neither short term  e.g. 8 or 24 hours or\\nlong term e.g. annual)  Individual\\nsensitivity to the health impacts of\\nparticulate matter can vary.\\n\\uf0b7Short-term exposure to particulate\\n\\nWhat are the factors affecting a \\nnormally  healthy person’s \\nvulnerability  to air pollution?  \\nPeople are more vulnerable to having \\nadverse health reactions to air pollution in \\nthe following situations :   \\n\\uf0b7 Particularly high c oncentration s of \\nparticulate matter . A number of \\nfactors, including  increased burning  of \\nfuel for winter, burning  of agricultural \\ncrop residues , as well as particular  \\nweather  patterns can all combine to \\ncreate air pollution peaks.  High \\nconcentrations of particulate matter are \\nmore often found in winter -time when \\nthe temperature and wi nd affect the \\nbuild -up of air pollution and its \\npersistence locally.  Normally, when air \\ngets colder, a layer of warm  air traps a \\nlayer of cold air nearer the ground. This \\nacts like a lid over a cloud of smog and \\nstops it from rising and drifting away .  \\n\\uf0b7 Close proximity  of activities \\ngenerating high levels of pollution \\nincluding:  \\no Heavy traffic on roads, vehicles not \\ncomplying to pollution norms;  \\no Thermal (coal-based ) power plants \\nand other factories emitting \\npolluting smoke;  \\no Uncontrolled construction or \\ndemolition sites;  \\no Use of biomass fuel for domestic \\nenergy needs  such as cooking ; \\no Bursting fire crackers;  o Burning waste from houses, \\nhospitals, electronic waste, crop \\nresidues , etc.  \\nWhat additional factors can \\naffect a person’s vulnerability ?  \\n\\uf0b7 Age of person  exposed : Children,  \\nespecially under -five, and older people \\nare particularly vulnerable.  \\n\\uf0b7 Health status of person exposed .  \\nPeople , with pre -existing diseases such \\nas asthma and other respiratory \\ndisease , cardiovascular diseases , are \\nat greater risk of heal th effects.   \\n\\uf0b7 Pregnant women . Evidence has \\nshown that pregnancy increases \\nvulnerability to the effects of particulate \\nexposure with potential effects to the\\nmatter (or PM) is likely to cause acute\\nhealth reactions such as irritation to the\\neyes, nose, and throat, coughing,\\nwheezing and increased frequency of\\nacute lower respiratory infections, deep\\nin your lungs.\\n\\uf0b7More prolonged and continued\\nexposure to either high or lower levels\\nof air pollution can also lead to an\\nincreased risk of respiratory infections ,\\nexacerbation of asthma, bronchitis or\\nserious chronic effects including\\nreduced lung function, ischaemic heart\\ndisease, stroke , lung cancer  and\\npremature death . Such symptoms are a\\nparticular concern in rural and peri-\\nurban settings where use of wood,\\nagricultural waste and animal dung is\\nused for cooking, heating and lighting\\nand exposure levels can be high and\\nprolonged over long periods of time.Updated  11 November 2019\\nunborn child such as low and pre -term \\nbirth weight . \\n\\uf0b7 Low socioeconomic status . Persons \\nwith low soci oeconomic status with a \\npre-existing disease,  poor nutritional \\nstatus  and poor housing conditions, \\nincluding where household combustion \\nof solid fuels takes place for cooking, \\nheating or lighting.  People living on the \\nstreet and in poor hous ing are \\nparticularly vulnerable.  \\n\\uf0b7 Occupational  exposures : Construction  \\nworkers, traffic police , road sweepers \\nand those working outdoors and in \\nhighly polluted settings . \\n\\uf0b7 Smoking of tobacco products  and \\nexposure to second -hand smoke'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you want to retrieve the top N results\n",
    " # Set this to the number of top results you want\n",
    "\n",
    "retriever = astra_vector_store.as_retriever()\n",
    "\n",
    "# Modify the invoke method to include a parameter for the number of top results\n",
    "results = retriever.invoke(\"What is Air Pollution\", ConsistencyLevel=\"LOCAL_ONE\")\n",
    "\n",
    "retrieved_content = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "# print(retrieved_content)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    # Split the text into lines and remove duplicate lines\n",
    "    lines = text.split('\\n')\n",
    "    unique_lines = list(OrderedDict.fromkeys(lines))  # Preserve the order and remove duplicates\n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "cleaned_text = remove_duplicates(retrieved_content)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: \"According to the provided fact sheet, air pollution is the contamination of the indoor or outdoor air by a range of gases and solids that modify its natural characteristics. Key health-harmful pollutants include particulate matter (PM2.5 and PM10), carbon monoxide (CO), ozone (O3), black carbon (BC), sulfur dioxide, and nitrogen oxides (NOx).\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-70b-versatile\")\n",
    "answer = astra_vector_index.query(\"What is Air Pollution\", llm=llm).strip()\n",
    "print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='pretrained_model'\n",
      "datasource='pretrained_model'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Set up ChatGroq for routing logic\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"pretrained_model\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to vectorstore or pretrained model.\",\n",
    "    )\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-70b-versatile\")\n",
    "structured_llm_router = llm.with_structured_output(schema=RouteQuery)\n",
    "# Define a schema for routing\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Schema to determine whether to route to vectorstore or pretrained model.\"\"\"\n",
    "    datasource: Literal[\"vectorstore\", \"pretrained_model\"]\n",
    "\n",
    "# Define a system prompt for routing\n",
    "system = \"\"\"You are an expert at routing a user question. \n",
    "Use the vectorstore for questions related to Prompt Engineering. \n",
    "else use pretrained model\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Specify the schema in with_structured_output\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"who is Sharukh Khan?\"}\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What is ML?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the LangGraph workflow\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Define GraphState\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    generation: str\n",
    "\n",
    "# Define the retrieve node (vectorstore querying)\n",
    "def retrieve(state):\n",
    "    print(\"---RETRIEVE FROM VECTORSTORE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    # Join document content into a single string to pass it to the LLM for question generation\n",
    "    retrieved_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    # Pass the retrieved content to ChatGroq for question generation\n",
    "    llm_prompt = f\"Based on the following document content, generate three questions:\\n{retrieved_content}\"\n",
    "    questions = llm.invoke(llm_prompt)\n",
    "    return {\"generation\": questions, \"question\": question}\n",
    "\n",
    "# Define the LLM query node (direct pretrained model query)\n",
    "def llm_query(state):\n",
    "    print(\"---PRETRAINED MODEL QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    llm_prompt = f\"Generate three questions about the topic: {question}\"\n",
    "    questions = llm.invoke(llm_prompt)\n",
    "    return {\"generation\": questions, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the routing node\n",
    "def route_question(state):\n",
    "    \n",
    "    print(\"---ROUTING QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # Routing based on topic\n",
    "    if source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE TO VECTOR STORE----\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"---ROUTE TO PRETRAINED MODEL----\")\n",
    "        return \"llm_query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# Step 6: Build LangGraph workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)  # Retrieve from vectorstore and pass to LLM\n",
    "workflow.add_node(\"llm_query\", llm_query)  # Query the LLM directly\n",
    "\n",
    "# Define conditional edges for routing\n",
    "workflow.add_conditional_edges(\n",
    "    START, route_question, {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"llm_query\": \"llm_query\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# End nodes after retrieval or LLM query\n",
    "workflow.add_edge(\"retrieve\", END)\n",
    "workflow.add_edge(\"llm_query\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTING QUESTION---\n",
      "---ROUTE TO VECTOR STORE----\n",
      "---RETRIEVE FROM VECTORSTORE---\n",
      "Node 'retrieve':\n",
      "{'question': 'Prompt Engineering', 'generation': AIMessage(content=\"Here are three questions based on the document content:\\n\\n1. What are some examples of occupational exposures that can increase a person's vulnerability to air pollution?\\n\\n2. How does low socioeconomic status affect a person's vulnerability to air pollution, and who is particularly vulnerable in this context?\\n\\n3. What are some specific weather patterns and seasonal factors that can contribute to high concentrations of particulate matter in the air, making people more vulnerable to air pollution?\", response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 1143, 'total_tokens': 1232, 'completion_time': 0.356, 'prompt_time': 0.285637751, 'queue_time': 0.005320676999999996, 'total_time': 0.641637751}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-180dc4b7-7a75-46cb-8462-1ed254a84203-0', usage_metadata={'input_tokens': 1143, 'output_tokens': 89, 'total_tokens': 1232})}\n"
     ]
    }
   ],
   "source": [
    "# # Step 7: Execute the workflow\n",
    "# inputs = {\n",
    "#     \"question\": \"Java\"\n",
    "# }\n",
    "# for output in app.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         print(f\"Node '{key}':\")\n",
    "#         print(value)\n",
    "\n",
    "# Example for querying ML topic\n",
    "inputs_ml = {\n",
    "    \"question\": \"Prompt Engineering\"\n",
    "}\n",
    "for output in app.stream(inputs_ml):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Node '{key}':\")\n",
    "        print(value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
